{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27295785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kasiv\\miniconda3\\envs\\py311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading engineered datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:35:40,295] A new study created in memory with name: no-name-87faf8fc-2037-4a49-b82e-fac0eab553ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Starting Optuna Optimization =====\n",
      "\n",
      "Optimizing XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:35:46,146] Trial 0 finished with value: 35.62168306639713 and parameters: {'n_estimators': 579, 'learning_rate': 0.078184652527901, 'max_depth': 8, 'subsample': 0.582718491947522, 'colsample_bytree': 0.738568867091161, 'min_child_weight': 8}. Best is trial 0 with value: 35.62168306639713.\n",
      "[I 2025-11-16 02:35:54,897] Trial 1 finished with value: 37.82877832958143 and parameters: {'n_estimators': 856, 'learning_rate': 0.2888576620845132, 'max_depth': 10, 'subsample': 0.5929235176530199, 'colsample_bytree': 0.8895539778774536, 'min_child_weight': 7}. Best is trial 0 with value: 35.62168306639713.\n",
      "[I 2025-11-16 02:35:58,253] Trial 2 finished with value: 36.81315560287557 and parameters: {'n_estimators': 732, 'learning_rate': 0.22694212945066927, 'max_depth': 4, 'subsample': 0.516282185452403, 'colsample_bytree': 0.7365879964699408, 'min_child_weight': 2}. Best is trial 0 with value: 35.62168306639713.\n",
      "[I 2025-11-16 02:36:08,757] Trial 3 finished with value: 37.31922680428703 and parameters: {'n_estimators': 1431, 'learning_rate': 0.2367486622759138, 'max_depth': 8, 'subsample': 0.5493262920910498, 'colsample_bytree': 0.8886618906378754, 'min_child_weight': 9}. Best is trial 0 with value: 35.62168306639713.\n",
      "[I 2025-11-16 02:36:23,990] Trial 4 finished with value: 37.98594067463376 and parameters: {'n_estimators': 1038, 'learning_rate': 0.27517326405679815, 'max_depth': 11, 'subsample': 0.593952624808276, 'colsample_bytree': 0.6075486908729575, 'min_child_weight': 5}. Best is trial 0 with value: 35.62168306639713.\n",
      "[I 2025-11-16 02:36:33,751] Trial 5 finished with value: 35.60271478678037 and parameters: {'n_estimators': 689, 'learning_rate': 0.033043644674018484, 'max_depth': 10, 'subsample': 0.6232117846313009, 'colsample_bytree': 0.5769712080029892, 'min_child_weight': 9}. Best is trial 5 with value: 35.60271478678037.\n",
      "[I 2025-11-16 02:36:47,703] Trial 6 finished with value: 36.02061049357926 and parameters: {'n_estimators': 1427, 'learning_rate': 0.14722014111470397, 'max_depth': 9, 'subsample': 0.9834343292577445, 'colsample_bytree': 0.648911339494357, 'min_child_weight': 2}. Best is trial 5 with value: 35.60271478678037.\n",
      "[I 2025-11-16 02:36:53,798] Trial 7 finished with value: 35.70534579321968 and parameters: {'n_estimators': 728, 'learning_rate': 0.10483866215235238, 'max_depth': 8, 'subsample': 0.7616561889895674, 'colsample_bytree': 0.5694839598676031, 'min_child_weight': 5}. Best is trial 5 with value: 35.60271478678037.\n",
      "[I 2025-11-16 02:37:14,514] Trial 8 finished with value: 36.89138222082471 and parameters: {'n_estimators': 1365, 'learning_rate': 0.09885733344199732, 'max_depth': 12, 'subsample': 0.8855903590128784, 'colsample_bytree': 0.6687436990144382, 'min_child_weight': 9}. Best is trial 5 with value: 35.60271478678037.\n",
      "[I 2025-11-16 02:37:30,099] Trial 9 finished with value: 39.02945230144278 and parameters: {'n_estimators': 1451, 'learning_rate': 0.27626219076149483, 'max_depth': 11, 'subsample': 0.8088575537705001, 'colsample_bytree': 0.887869727121698, 'min_child_weight': 10}. Best is trial 5 with value: 35.60271478678037.\n",
      "[I 2025-11-16 02:37:32,884] Trial 10 finished with value: 34.396187440095495 and parameters: {'n_estimators': 461, 'learning_rate': 0.03478147011461496, 'max_depth': 6, 'subsample': 0.6818644679482031, 'colsample_bytree': 0.5156235072365467, 'min_child_weight': 6}. Best is trial 10 with value: 34.396187440095495.\n",
      "[I 2025-11-16 02:37:35,203] Trial 11 finished with value: 33.90454755482551 and parameters: {'n_estimators': 414, 'learning_rate': 0.024029507071922283, 'max_depth': 5, 'subsample': 0.6666029243676295, 'colsample_bytree': 0.5005821810071807, 'min_child_weight': 6}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:37:37,662] Trial 12 finished with value: 34.03132675162186 and parameters: {'n_estimators': 464, 'learning_rate': 0.029463265567664224, 'max_depth': 5, 'subsample': 0.6837051791729127, 'colsample_bytree': 0.5063333311985989, 'min_child_weight': 6}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:37:40,014] Trial 13 finished with value: 34.01242925391693 and parameters: {'n_estimators': 411, 'learning_rate': 0.015090993809180078, 'max_depth': 4, 'subsample': 0.6951481276363537, 'colsample_bytree': 0.5178756889394585, 'min_child_weight': 4}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:37:46,372] Trial 14 finished with value: 35.4671929788283 and parameters: {'n_estimators': 1081, 'learning_rate': 0.06894209921704081, 'max_depth': 6, 'subsample': 0.6947074987206128, 'colsample_bytree': 0.814348005318631, 'min_child_weight': 4}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:37:48,357] Trial 15 finished with value: 34.34066263229543 and parameters: {'n_estimators': 405, 'learning_rate': 0.01112269801995553, 'max_depth': 4, 'subsample': 0.8190188968793572, 'colsample_bytree': 0.5005543944214247, 'min_child_weight': 3}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:37:51,718] Trial 16 finished with value: 36.797136771779485 and parameters: {'n_estimators': 583, 'learning_rate': 0.15183420414735543, 'max_depth': 6, 'subsample': 0.7460755503108737, 'colsample_bytree': 0.6572731967701506, 'min_child_weight': 1}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:37:58,026] Trial 17 finished with value: 36.95311547300663 and parameters: {'n_estimators': 1234, 'learning_rate': 0.18646394054586798, 'max_depth': 5, 'subsample': 0.6658733738268513, 'colsample_bytree': 0.9830882775595458, 'min_child_weight': 4}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:38:04,011] Trial 18 finished with value: 35.581683463320886 and parameters: {'n_estimators': 882, 'learning_rate': 0.06892471955721198, 'max_depth': 7, 'subsample': 0.7422976754329043, 'colsample_bytree': 0.5604137132783209, 'min_child_weight': 7}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:38:06,411] Trial 19 finished with value: 35.353571624106166 and parameters: {'n_estimators': 564, 'learning_rate': 0.12685745499054815, 'max_depth': 4, 'subsample': 0.8809980694908438, 'colsample_bytree': 0.6980196405032892, 'min_child_weight': 4}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:38:09,659] Trial 20 finished with value: 36.10094849294745 and parameters: {'n_estimators': 641, 'learning_rate': 0.18784364458677472, 'max_depth': 5, 'subsample': 0.6491323015230112, 'colsample_bytree': 0.6168269694453865, 'min_child_weight': 7}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:38:12,440] Trial 21 finished with value: 34.16612797542628 and parameters: {'n_estimators': 492, 'learning_rate': 0.01009453708553451, 'max_depth': 5, 'subsample': 0.7111231318870168, 'colsample_bytree': 0.5291393825761437, 'min_child_weight': 6}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:38:14,614] Trial 22 finished with value: 34.0168523173944 and parameters: {'n_estimators': 417, 'learning_rate': 0.05158678713288932, 'max_depth': 5, 'subsample': 0.6387836083605966, 'colsample_bytree': 0.5008143440848702, 'min_child_weight': 5}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:38:17,881] Trial 23 finished with value: 34.67656760474085 and parameters: {'n_estimators': 403, 'learning_rate': 0.04640674669870076, 'max_depth': 7, 'subsample': 0.6259114341464369, 'colsample_bytree': 0.5523038041452208, 'min_child_weight': 3}. Best is trial 11 with value: 33.90454755482551.\n",
      "[I 2025-11-16 02:38:20,290] Trial 24 finished with value: 33.764019621477374 and parameters: {'n_estimators': 549, 'learning_rate': 0.049150029290415675, 'max_depth': 4, 'subsample': 0.783097370447511, 'colsample_bytree': 0.5904194910801459, 'min_child_weight': 5}. Best is trial 24 with value: 33.764019621477374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best XGBoost params: {'n_estimators': 549, 'learning_rate': 0.049150029290415675, 'max_depth': 4, 'subsample': 0.783097370447511, 'colsample_bytree': 0.5904194910801459, 'min_child_weight': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:38:22,904] A new study created in memory with name: no-name-f852d2b2-4b12-4575-b822-e06d0bf0464e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:38:33,448] Trial 0 finished with value: 36.3945925279907 and parameters: {'n_estimators': 815, 'learning_rate': 0.1371468067792225, 'num_leaves': 67, 'subsample': 0.5886091822806909, 'colsample_bytree': 0.5050416871600665, 'min_child_samples': 35}. Best is trial 0 with value: 36.3945925279907.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:38:45,005] Trial 1 finished with value: 36.81710632621451 and parameters: {'n_estimators': 1008, 'learning_rate': 0.1703377589441559, 'num_leaves': 131, 'subsample': 0.8706537922313566, 'colsample_bytree': 0.8774626910887408, 'min_child_samples': 32}. Best is trial 0 with value: 36.3945925279907.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:38:50,696] Trial 2 finished with value: 37.207293719889506 and parameters: {'n_estimators': 426, 'learning_rate': 0.16161431879792157, 'num_leaves': 162, 'subsample': 0.6359378172019788, 'colsample_bytree': 0.6712663476673537, 'min_child_samples': 46}. Best is trial 0 with value: 36.3945925279907.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:39:02,781] Trial 3 finished with value: 36.650095470508084 and parameters: {'n_estimators': 873, 'learning_rate': 0.1274008635506955, 'num_leaves': 167, 'subsample': 0.8907179168572947, 'colsample_bytree': 0.8059843202609027, 'min_child_samples': 16}. Best is trial 0 with value: 36.3945925279907.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:39:12,109] Trial 4 finished with value: 35.7917859459516 and parameters: {'n_estimators': 774, 'learning_rate': 0.036237021033281, 'num_leaves': 127, 'subsample': 0.6159739473808066, 'colsample_bytree': 0.8818194702442455, 'min_child_samples': 28}. Best is trial 4 with value: 35.7917859459516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:39:31,425] Trial 5 finished with value: 37.16011985788883 and parameters: {'n_estimators': 1305, 'learning_rate': 0.26131583291028504, 'num_leaves': 200, 'subsample': 0.9540487022354793, 'colsample_bytree': 0.720179764235083, 'min_child_samples': 32}. Best is trial 4 with value: 35.7917859459516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:39:39,912] Trial 6 finished with value: 35.22921213407288 and parameters: {'n_estimators': 868, 'learning_rate': 0.030585676108803146, 'num_leaves': 92, 'subsample': 0.6631206068839133, 'colsample_bytree': 0.7225533267496866, 'min_child_samples': 12}. Best is trial 6 with value: 35.22921213407288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:39:47,135] Trial 7 finished with value: 38.29954121488205 and parameters: {'n_estimators': 641, 'learning_rate': 0.2954375962645279, 'num_leaves': 128, 'subsample': 0.9832384324544337, 'colsample_bytree': 0.6412793003077715, 'min_child_samples': 47}. Best is trial 6 with value: 35.22921213407288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:39:58,221] Trial 8 finished with value: 37.68886392476011 and parameters: {'n_estimators': 760, 'learning_rate': 0.2361391172519558, 'num_leaves': 196, 'subsample': 0.6637066578643056, 'colsample_bytree': 0.6230829636977107, 'min_child_samples': 34}. Best is trial 6 with value: 35.22921213407288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:40:08,914] Trial 9 finished with value: 36.208234116956795 and parameters: {'n_estimators': 1467, 'learning_rate': 0.12736008774668126, 'num_leaves': 65, 'subsample': 0.8199371003239149, 'colsample_bytree': 0.7425000317199035, 'min_child_samples': 41}. Best is trial 6 with value: 35.22921213407288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:40:14,702] Trial 10 finished with value: 34.15581940298573 and parameters: {'n_estimators': 1111, 'learning_rate': 0.018903677096045894, 'num_leaves': 21, 'subsample': 0.7495891571473323, 'colsample_bytree': 0.9518364750447124, 'min_child_samples': 5}. Best is trial 10 with value: 34.15581940298573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:40:20,485] Trial 11 finished with value: 34.14238771007745 and parameters: {'n_estimators': 1131, 'learning_rate': 0.02327413699577415, 'num_leaves': 22, 'subsample': 0.7381138647942795, 'colsample_bytree': 0.9917188439213516, 'min_child_samples': 5}. Best is trial 11 with value: 34.14238771007745.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:40:25,819] Trial 12 finished with value: 35.00646807747352 and parameters: {'n_estimators': 1136, 'learning_rate': 0.07672608529911518, 'num_leaves': 21, 'subsample': 0.7536407224482672, 'colsample_bytree': 0.9909296471193634, 'min_child_samples': 5}. Best is trial 11 with value: 34.14238771007745.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:40:31,968] Trial 13 finished with value: 34.018653122352326 and parameters: {'n_estimators': 1156, 'learning_rate': 0.015012857952132645, 'num_leaves': 21, 'subsample': 0.5070949436956307, 'colsample_bytree': 0.9996847831710932, 'min_child_samples': 18}. Best is trial 13 with value: 34.018653122352326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:40:40,586] Trial 14 finished with value: 35.41400901741426 and parameters: {'n_estimators': 1269, 'learning_rate': 0.07704529029001962, 'num_leaves': 53, 'subsample': 0.5147078029714127, 'colsample_bytree': 0.9203784738810856, 'min_child_samples': 20}. Best is trial 13 with value: 34.018653122352326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:40:48,184] Trial 15 finished with value: 35.52639396497729 and parameters: {'n_estimators': 1252, 'learning_rate': 0.06979916441026612, 'num_leaves': 42, 'subsample': 0.5184569457250847, 'colsample_bytree': 0.9949281256013969, 'min_child_samples': 19}. Best is trial 13 with value: 34.018653122352326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:40:59,339] Trial 16 finished with value: 35.03429259609541 and parameters: {'n_estimators': 1029, 'learning_rate': 0.010701685983826509, 'num_leaves': 93, 'subsample': 0.7321574362815395, 'colsample_bytree': 0.8210624474674545, 'min_child_samples': 11}. Best is trial 13 with value: 34.018653122352326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:41:07,695] Trial 17 finished with value: 35.15368666656627 and parameters: {'n_estimators': 1444, 'learning_rate': 0.05965518153893269, 'num_leaves': 38, 'subsample': 0.8117617112416438, 'colsample_bytree': 0.8362306966131534, 'min_child_samples': 24}. Best is trial 13 with value: 34.018653122352326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:41:17,716] Trial 18 finished with value: 36.251295892884784 and parameters: {'n_estimators': 1171, 'learning_rate': 0.09915425366393035, 'num_leaves': 83, 'subsample': 0.5654360935192585, 'colsample_bytree': 0.9435865370108995, 'min_child_samples': 13}. Best is trial 13 with value: 34.018653122352326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:41:25,835] Trial 19 finished with value: 37.32433918453044 and parameters: {'n_estimators': 1374, 'learning_rate': 0.20864697137184077, 'num_leaves': 42, 'subsample': 0.7037948098258096, 'colsample_bytree': 0.8914761835043957, 'min_child_samples': 9}. Best is trial 13 with value: 34.018653122352326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:41:32,951] Trial 20 finished with value: 35.43158523820695 and parameters: {'n_estimators': 986, 'learning_rate': 0.05072079665369232, 'num_leaves': 71, 'subsample': 0.7979636362196969, 'colsample_bytree': 0.5271545443253354, 'min_child_samples': 24}. Best is trial 13 with value: 34.018653122352326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:41:39,187] Trial 21 finished with value: 33.986911759932724 and parameters: {'n_estimators': 1112, 'learning_rate': 0.013924591953908357, 'num_leaves': 22, 'subsample': 0.7102646648686131, 'colsample_bytree': 0.9571760096590847, 'min_child_samples': 5}. Best is trial 21 with value: 33.986911759932724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:41:44,913] Trial 22 finished with value: 35.958863849169056 and parameters: {'n_estimators': 1082, 'learning_rate': 0.09671771587178524, 'num_leaves': 29, 'subsample': 0.7011406980784065, 'colsample_bytree': 0.9998867094905363, 'min_child_samples': 9}. Best is trial 21 with value: 33.986911759932724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:41:54,457] Trial 23 finished with value: 34.487784784013755 and parameters: {'n_estimators': 1200, 'learning_rate': 0.010031693080123312, 'num_leaves': 51, 'subsample': 0.558680014830333, 'colsample_bytree': 0.9383023667883513, 'min_child_samples': 16}. Best is trial 21 with value: 33.986911759932724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:42:02,162] Trial 24 finished with value: 35.21704312031135 and parameters: {'n_estimators': 1356, 'learning_rate': 0.04087188532198815, 'num_leaves': 33, 'subsample': 0.8707924269590243, 'colsample_bytree': 0.9630443839692763, 'min_child_samples': 5}. Best is trial 21 with value: 33.986911759932724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM params: {'n_estimators': 1112, 'learning_rate': 0.013924591953908357, 'num_leaves': 22, 'subsample': 0.7102646648686131, 'colsample_bytree': 0.9571760096590847, 'min_child_samples': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4759\n",
      "[LightGBM] [Info] Number of data points in the train set: 226523, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 203.309682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:42:08,392] A new study created in memory with name: no-name-e7630c76-ee2d-4e57-82ed-bd867744f81a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 02:42:39,680] Trial 0 finished with value: 34.58859338212515 and parameters: {'iterations': 689, 'depth': 9, 'learning_rate': 0.1026939054493498, 'l2_leaf_reg': 5.967057782975131}. Best is trial 0 with value: 34.58859338212515.\n",
      "[I 2025-11-16 02:43:02,000] Trial 1 finished with value: 33.43581581632715 and parameters: {'iterations': 943, 'depth': 5, 'learning_rate': 0.053683349852451816, 'l2_leaf_reg': 9.662511600333946}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:43:29,505] Trial 2 finished with value: 35.30437168484631 and parameters: {'iterations': 1126, 'depth': 5, 'learning_rate': 0.18294198029510714, 'l2_leaf_reg': 1.8987716640291092}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:44:12,757] Trial 3 finished with value: 35.33584817328405 and parameters: {'iterations': 1432, 'depth': 7, 'learning_rate': 0.19089948962689818, 'l2_leaf_reg': 5.124037409395573}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:44:40,213] Trial 4 finished with value: 34.366805282435514 and parameters: {'iterations': 610, 'depth': 9, 'learning_rate': 0.17299454422565888, 'l2_leaf_reg': 8.456290545952601}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:45:12,911] Trial 5 finished with value: 36.062087825574096 and parameters: {'iterations': 1341, 'depth': 5, 'learning_rate': 0.274055958992043, 'l2_leaf_reg': 2.9029091545749806}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:46:06,323] Trial 6 finished with value: 35.78716422307122 and parameters: {'iterations': 1187, 'depth': 9, 'learning_rate': 0.25378570523047517, 'l2_leaf_reg': 7.8506823270364325}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:46:22,862] Trial 7 finished with value: 34.69106611954556 and parameters: {'iterations': 682, 'depth': 5, 'learning_rate': 0.16491233061378013, 'l2_leaf_reg': 7.501530708612707}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:46:35,962] Trial 8 finished with value: 34.727984687823415 and parameters: {'iterations': 665, 'depth': 4, 'learning_rate': 0.23605843538547006, 'l2_leaf_reg': 3.5620190979833075}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:47:04,996] Trial 9 finished with value: 34.70614656727814 and parameters: {'iterations': 782, 'depth': 8, 'learning_rate': 0.15755703024521717, 'l2_leaf_reg': 4.558977094842405}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:47:34,382] Trial 10 finished with value: 33.60611680703053 and parameters: {'iterations': 946, 'depth': 7, 'learning_rate': 0.03241583311400955, 'l2_leaf_reg': 9.949801522673313}. Best is trial 1 with value: 33.43581581632715.\n",
      "[I 2025-11-16 02:48:03,105] Trial 11 finished with value: 33.08324759004148 and parameters: {'iterations': 949, 'depth': 7, 'learning_rate': 0.01604773295661959, 'l2_leaf_reg': 9.928800869663316}. Best is trial 11 with value: 33.08324759004148.\n",
      "[I 2025-11-16 02:48:30,109] Trial 12 finished with value: 33.14412272102333 and parameters: {'iterations': 986, 'depth': 6, 'learning_rate': 0.015586545184926793, 'l2_leaf_reg': 9.87343770700055}. Best is trial 11 with value: 33.08324759004148.\n",
      "[I 2025-11-16 02:48:42,374] Trial 13 finished with value: 33.725850144197715 and parameters: {'iterations': 429, 'depth': 6, 'learning_rate': 0.08706190341364337, 'l2_leaf_reg': 6.671470201189347}. Best is trial 11 with value: 33.08324759004148.\n",
      "[I 2025-11-16 02:49:16,713] Trial 14 finished with value: 33.1416835314879 and parameters: {'iterations': 1095, 'depth': 7, 'learning_rate': 0.019350305179443326, 'l2_leaf_reg': 8.762368779276859}. Best is trial 11 with value: 33.08324759004148.\n",
      "[I 2025-11-16 02:49:53,774] Trial 15 finished with value: 34.17466613405886 and parameters: {'iterations': 1176, 'depth': 7, 'learning_rate': 0.10279136733258065, 'l2_leaf_reg': 9.017358450376172}. Best is trial 11 with value: 33.08324759004148.\n",
      "[I 2025-11-16 02:50:25,362] Trial 16 finished with value: 33.887061355462976 and parameters: {'iterations': 854, 'depth': 8, 'learning_rate': 0.06189334477558216, 'l2_leaf_reg': 7.046601375663956}. Best is trial 11 with value: 33.08324759004148.\n",
      "[I 2025-11-16 02:51:50,466] Trial 17 finished with value: 33.32437192796409 and parameters: {'iterations': 1098, 'depth': 10, 'learning_rate': 0.011251716782198561, 'l2_leaf_reg': 8.726113673057883}. Best is trial 11 with value: 33.08324759004148.\n",
      "[I 2025-11-16 02:52:38,652] Trial 18 finished with value: 35.25104698789046 and parameters: {'iterations': 1314, 'depth': 8, 'learning_rate': 0.11851837384162518, 'l2_leaf_reg': 8.124533555365398}. Best is trial 11 with value: 33.08324759004148.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best CatBoost params: {'iterations': 949, 'depth': 7, 'learning_rate': 0.01604773295661959, 'l2_leaf_reg': 9.928800869663316}\n",
      "0:\tlearn: 82.8384326\ttotal: 39.1ms\tremaining: 37s\n",
      "1:\tlearn: 81.7859630\ttotal: 70.9ms\tremaining: 33.6s\n",
      "2:\tlearn: 80.7461518\ttotal: 102ms\tremaining: 32.1s\n",
      "3:\tlearn: 79.7267345\ttotal: 132ms\tremaining: 31.2s\n",
      "4:\tlearn: 78.7263413\ttotal: 163ms\tremaining: 30.8s\n",
      "5:\tlearn: 77.7484581\ttotal: 193ms\tremaining: 30.4s\n",
      "6:\tlearn: 76.7965072\ttotal: 223ms\tremaining: 30s\n",
      "7:\tlearn: 75.8501887\ttotal: 252ms\tremaining: 29.7s\n",
      "8:\tlearn: 74.9278022\ttotal: 282ms\tremaining: 29.4s\n",
      "9:\tlearn: 74.0263973\ttotal: 313ms\tremaining: 29.4s\n",
      "10:\tlearn: 73.1397527\ttotal: 343ms\tremaining: 29.2s\n",
      "11:\tlearn: 72.2729917\ttotal: 375ms\tremaining: 29.3s\n",
      "12:\tlearn: 71.4248915\ttotal: 404ms\tremaining: 29.1s\n",
      "13:\tlearn: 70.5952780\ttotal: 434ms\tremaining: 29s\n",
      "14:\tlearn: 69.7722990\ttotal: 463ms\tremaining: 28.8s\n",
      "15:\tlearn: 68.9694776\ttotal: 497ms\tremaining: 29s\n",
      "16:\tlearn: 68.1745701\ttotal: 528ms\tremaining: 29s\n",
      "17:\tlearn: 67.4101191\ttotal: 558ms\tremaining: 28.8s\n",
      "18:\tlearn: 66.6475696\ttotal: 587ms\tremaining: 28.7s\n",
      "19:\tlearn: 65.9064864\ttotal: 617ms\tremaining: 28.7s\n",
      "20:\tlearn: 65.1831569\ttotal: 646ms\tremaining: 28.6s\n",
      "21:\tlearn: 64.4706069\ttotal: 677ms\tremaining: 28.5s\n",
      "22:\tlearn: 63.7808547\ttotal: 706ms\tremaining: 28.4s\n",
      "23:\tlearn: 63.0959640\ttotal: 738ms\tremaining: 28.4s\n",
      "24:\tlearn: 62.4237415\ttotal: 768ms\tremaining: 28.4s\n",
      "25:\tlearn: 61.7600892\ttotal: 799ms\tremaining: 28.4s\n",
      "26:\tlearn: 61.1184763\ttotal: 829ms\tremaining: 28.3s\n",
      "27:\tlearn: 60.4906133\ttotal: 859ms\tremaining: 28.2s\n",
      "28:\tlearn: 59.8776498\ttotal: 888ms\tremaining: 28.2s\n",
      "29:\tlearn: 59.2819990\ttotal: 918ms\tremaining: 28.1s\n",
      "30:\tlearn: 58.6942222\ttotal: 948ms\tremaining: 28.1s\n",
      "31:\tlearn: 58.1148217\ttotal: 979ms\tremaining: 28s\n",
      "32:\tlearn: 57.5495829\ttotal: 1.01s\tremaining: 28s\n",
      "33:\tlearn: 57.0030118\ttotal: 1.04s\tremaining: 27.9s\n",
      "34:\tlearn: 56.4587520\ttotal: 1.09s\tremaining: 28.6s\n",
      "35:\tlearn: 55.9296291\ttotal: 1.15s\tremaining: 29s\n",
      "36:\tlearn: 55.4102007\ttotal: 1.19s\tremaining: 29.2s\n",
      "37:\tlearn: 54.9112224\ttotal: 1.22s\tremaining: 29.3s\n",
      "38:\tlearn: 54.4171381\ttotal: 1.26s\tremaining: 29.4s\n",
      "39:\tlearn: 53.9370240\ttotal: 1.3s\tremaining: 29.6s\n",
      "40:\tlearn: 53.4586540\ttotal: 1.34s\tremaining: 29.6s\n",
      "41:\tlearn: 52.9917546\ttotal: 1.38s\tremaining: 29.7s\n",
      "42:\tlearn: 52.5412143\ttotal: 1.41s\tremaining: 29.6s\n",
      "43:\tlearn: 52.0891824\ttotal: 1.44s\tremaining: 29.6s\n",
      "44:\tlearn: 51.6542534\ttotal: 1.47s\tremaining: 29.5s\n",
      "45:\tlearn: 51.2372664\ttotal: 1.5s\tremaining: 29.5s\n",
      "46:\tlearn: 50.8203332\ttotal: 1.53s\tremaining: 29.4s\n",
      "47:\tlearn: 50.4100103\ttotal: 1.56s\tremaining: 29.4s\n",
      "48:\tlearn: 50.0154862\ttotal: 1.59s\tremaining: 29.3s\n",
      "49:\tlearn: 49.6216226\ttotal: 1.62s\tremaining: 29.2s\n",
      "50:\tlearn: 49.2424878\ttotal: 1.65s\tremaining: 29.1s\n",
      "51:\tlearn: 48.8742556\ttotal: 1.68s\tremaining: 29.1s\n",
      "52:\tlearn: 48.5098482\ttotal: 1.72s\tremaining: 29s\n",
      "53:\tlearn: 48.1532999\ttotal: 1.75s\tremaining: 28.9s\n",
      "54:\tlearn: 47.8050457\ttotal: 1.78s\tremaining: 28.9s\n",
      "55:\tlearn: 47.4606947\ttotal: 1.8s\tremaining: 28.8s\n",
      "56:\tlearn: 47.1370780\ttotal: 1.83s\tremaining: 28.7s\n",
      "57:\tlearn: 46.8141586\ttotal: 1.86s\tremaining: 28.7s\n",
      "58:\tlearn: 46.4961994\ttotal: 1.9s\tremaining: 28.6s\n",
      "59:\tlearn: 46.1873760\ttotal: 1.93s\tremaining: 28.5s\n",
      "60:\tlearn: 45.8866127\ttotal: 1.96s\tremaining: 28.6s\n",
      "61:\tlearn: 45.6015254\ttotal: 1.99s\tremaining: 28.5s\n",
      "62:\tlearn: 45.3140979\ttotal: 2.03s\tremaining: 28.5s\n",
      "63:\tlearn: 45.0321418\ttotal: 2.06s\tremaining: 28.5s\n",
      "64:\tlearn: 44.7616434\ttotal: 2.09s\tremaining: 28.5s\n",
      "65:\tlearn: 44.4985362\ttotal: 2.12s\tremaining: 28.4s\n",
      "66:\tlearn: 44.2358632\ttotal: 2.15s\tremaining: 28.3s\n",
      "67:\tlearn: 43.9814448\ttotal: 2.18s\tremaining: 28.3s\n",
      "68:\tlearn: 43.7345182\ttotal: 2.21s\tremaining: 28.2s\n",
      "69:\tlearn: 43.4916786\ttotal: 2.24s\tremaining: 28.2s\n",
      "70:\tlearn: 43.2557982\ttotal: 2.27s\tremaining: 28.1s\n",
      "71:\tlearn: 43.0226476\ttotal: 2.3s\tremaining: 28.1s\n",
      "72:\tlearn: 42.7988721\ttotal: 2.33s\tremaining: 28s\n",
      "73:\tlearn: 42.5782937\ttotal: 2.39s\tremaining: 28.3s\n",
      "74:\tlearn: 42.3697748\ttotal: 2.44s\tremaining: 28.5s\n",
      "75:\tlearn: 42.1592986\ttotal: 2.49s\tremaining: 28.6s\n",
      "76:\tlearn: 41.9519485\ttotal: 2.53s\tremaining: 28.7s\n",
      "77:\tlearn: 41.7526040\ttotal: 2.57s\tremaining: 28.8s\n",
      "78:\tlearn: 41.5579209\ttotal: 2.61s\tremaining: 28.8s\n",
      "79:\tlearn: 41.3671497\ttotal: 2.65s\tremaining: 28.7s\n",
      "80:\tlearn: 41.1878591\ttotal: 2.68s\tremaining: 28.7s\n",
      "81:\tlearn: 41.0079992\ttotal: 2.71s\tremaining: 28.7s\n",
      "82:\tlearn: 40.8273088\ttotal: 2.74s\tremaining: 28.6s\n",
      "83:\tlearn: 40.6549881\ttotal: 2.78s\tremaining: 28.6s\n",
      "84:\tlearn: 40.4832707\ttotal: 2.81s\tremaining: 28.6s\n",
      "85:\tlearn: 40.3212499\ttotal: 2.84s\tremaining: 28.5s\n",
      "86:\tlearn: 40.1603320\ttotal: 2.87s\tremaining: 28.5s\n",
      "87:\tlearn: 40.0061091\ttotal: 2.9s\tremaining: 28.4s\n",
      "88:\tlearn: 39.8517637\ttotal: 2.93s\tremaining: 28.4s\n",
      "89:\tlearn: 39.7086540\ttotal: 2.96s\tremaining: 28.3s\n",
      "90:\tlearn: 39.5653625\ttotal: 2.99s\tremaining: 28.2s\n",
      "91:\tlearn: 39.4230870\ttotal: 3.02s\tremaining: 28.1s\n",
      "92:\tlearn: 39.2879706\ttotal: 3.05s\tremaining: 28.1s\n",
      "93:\tlearn: 39.1533516\ttotal: 3.08s\tremaining: 28s\n",
      "94:\tlearn: 39.0233478\ttotal: 3.11s\tremaining: 28s\n",
      "95:\tlearn: 38.8940351\ttotal: 3.14s\tremaining: 27.9s\n",
      "96:\tlearn: 38.7659113\ttotal: 3.17s\tremaining: 27.8s\n",
      "97:\tlearn: 38.6460573\ttotal: 3.2s\tremaining: 27.8s\n",
      "98:\tlearn: 38.5265874\ttotal: 3.23s\tremaining: 27.7s\n",
      "99:\tlearn: 38.4084027\ttotal: 3.26s\tremaining: 27.7s\n",
      "100:\tlearn: 38.2933980\ttotal: 3.29s\tremaining: 27.6s\n",
      "101:\tlearn: 38.1800257\ttotal: 3.32s\tremaining: 27.6s\n",
      "102:\tlearn: 38.0712653\ttotal: 3.35s\tremaining: 27.5s\n",
      "103:\tlearn: 37.9650061\ttotal: 3.38s\tremaining: 27.5s\n",
      "104:\tlearn: 37.8589535\ttotal: 3.41s\tremaining: 27.4s\n",
      "105:\tlearn: 37.7584596\ttotal: 3.44s\tremaining: 27.4s\n",
      "106:\tlearn: 37.6621007\ttotal: 3.47s\tremaining: 27.3s\n",
      "107:\tlearn: 37.5643995\ttotal: 3.5s\tremaining: 27.3s\n",
      "108:\tlearn: 37.4627968\ttotal: 3.53s\tremaining: 27.2s\n",
      "109:\tlearn: 37.3750291\ttotal: 3.56s\tremaining: 27.1s\n",
      "110:\tlearn: 37.2865333\ttotal: 3.59s\tremaining: 27.1s\n",
      "111:\tlearn: 37.1990879\ttotal: 3.62s\tremaining: 27s\n",
      "112:\tlearn: 37.1128006\ttotal: 3.65s\tremaining: 27s\n",
      "113:\tlearn: 37.0284913\ttotal: 3.68s\tremaining: 26.9s\n",
      "114:\tlearn: 36.9453617\ttotal: 3.71s\tremaining: 26.9s\n",
      "115:\tlearn: 36.8623336\ttotal: 3.73s\tremaining: 26.8s\n",
      "116:\tlearn: 36.7812009\ttotal: 3.77s\tremaining: 26.8s\n",
      "117:\tlearn: 36.6989839\ttotal: 3.79s\tremaining: 26.7s\n",
      "118:\tlearn: 36.6182660\ttotal: 3.82s\tremaining: 26.7s\n",
      "119:\tlearn: 36.5502208\ttotal: 3.85s\tremaining: 26.6s\n",
      "120:\tlearn: 36.4828275\ttotal: 3.88s\tremaining: 26.6s\n",
      "121:\tlearn: 36.4121549\ttotal: 3.91s\tremaining: 26.5s\n",
      "122:\tlearn: 36.3477356\ttotal: 3.94s\tremaining: 26.4s\n",
      "123:\tlearn: 36.2813369\ttotal: 3.97s\tremaining: 26.4s\n",
      "124:\tlearn: 36.2124721\ttotal: 4.02s\tremaining: 26.5s\n",
      "125:\tlearn: 36.1460203\ttotal: 4.05s\tremaining: 26.4s\n",
      "126:\tlearn: 36.0778149\ttotal: 4.08s\tremaining: 26.4s\n",
      "127:\tlearn: 36.0150887\ttotal: 4.11s\tremaining: 26.4s\n",
      "128:\tlearn: 35.9540447\ttotal: 4.14s\tremaining: 26.3s\n",
      "129:\tlearn: 35.8920451\ttotal: 4.17s\tremaining: 26.3s\n",
      "130:\tlearn: 35.8312311\ttotal: 4.2s\tremaining: 26.3s\n",
      "131:\tlearn: 35.7750829\ttotal: 4.24s\tremaining: 26.2s\n",
      "132:\tlearn: 35.7250060\ttotal: 4.26s\tremaining: 26.2s\n",
      "133:\tlearn: 35.6642350\ttotal: 4.29s\tremaining: 26.1s\n",
      "134:\tlearn: 35.6120636\ttotal: 4.32s\tremaining: 26.1s\n",
      "135:\tlearn: 35.5635275\ttotal: 4.35s\tremaining: 26s\n",
      "136:\tlearn: 35.5136759\ttotal: 4.38s\tremaining: 26s\n",
      "137:\tlearn: 35.4678200\ttotal: 4.41s\tremaining: 25.9s\n",
      "138:\tlearn: 35.4152385\ttotal: 4.44s\tremaining: 25.9s\n",
      "139:\tlearn: 35.3641277\ttotal: 4.47s\tremaining: 25.8s\n",
      "140:\tlearn: 35.3166889\ttotal: 4.5s\tremaining: 25.8s\n",
      "141:\tlearn: 35.2699774\ttotal: 4.53s\tremaining: 25.7s\n",
      "142:\tlearn: 35.2207135\ttotal: 4.56s\tremaining: 25.7s\n",
      "143:\tlearn: 35.1726004\ttotal: 4.59s\tremaining: 25.6s\n",
      "144:\tlearn: 35.1287152\ttotal: 4.61s\tremaining: 25.6s\n",
      "145:\tlearn: 35.0872436\ttotal: 4.64s\tremaining: 25.5s\n",
      "146:\tlearn: 35.0441765\ttotal: 4.67s\tremaining: 25.5s\n",
      "147:\tlearn: 34.9954162\ttotal: 4.7s\tremaining: 25.4s\n",
      "148:\tlearn: 34.9544946\ttotal: 4.73s\tremaining: 25.4s\n",
      "149:\tlearn: 34.9109108\ttotal: 4.76s\tremaining: 25.4s\n",
      "150:\tlearn: 34.8754864\ttotal: 4.79s\tremaining: 25.3s\n",
      "151:\tlearn: 34.8413743\ttotal: 4.82s\tremaining: 25.2s\n",
      "152:\tlearn: 34.8047506\ttotal: 4.84s\tremaining: 25.2s\n",
      "153:\tlearn: 34.7619598\ttotal: 4.87s\tremaining: 25.1s\n",
      "154:\tlearn: 34.7233168\ttotal: 4.9s\tremaining: 25.1s\n",
      "155:\tlearn: 34.6777458\ttotal: 4.93s\tremaining: 25.1s\n",
      "156:\tlearn: 34.6439385\ttotal: 4.98s\tremaining: 25.1s\n",
      "157:\tlearn: 34.6084735\ttotal: 5.03s\tremaining: 25.2s\n",
      "158:\tlearn: 34.5686802\ttotal: 5.07s\tremaining: 25.2s\n",
      "159:\tlearn: 34.5331241\ttotal: 5.11s\tremaining: 25.2s\n",
      "160:\tlearn: 34.4975932\ttotal: 5.15s\tremaining: 25.2s\n",
      "161:\tlearn: 34.4661799\ttotal: 5.19s\tremaining: 25.2s\n",
      "162:\tlearn: 34.4325171\ttotal: 5.22s\tremaining: 25.2s\n",
      "163:\tlearn: 34.3961583\ttotal: 5.26s\tremaining: 25.2s\n",
      "164:\tlearn: 34.3650433\ttotal: 5.29s\tremaining: 25.1s\n",
      "165:\tlearn: 34.3297958\ttotal: 5.32s\tremaining: 25.1s\n",
      "166:\tlearn: 34.3003243\ttotal: 5.35s\tremaining: 25s\n",
      "167:\tlearn: 34.2785303\ttotal: 5.38s\tremaining: 25s\n",
      "168:\tlearn: 34.2506616\ttotal: 5.41s\tremaining: 25s\n",
      "169:\tlearn: 34.2187275\ttotal: 5.44s\tremaining: 24.9s\n",
      "170:\tlearn: 34.1878482\ttotal: 5.46s\tremaining: 24.9s\n",
      "171:\tlearn: 34.1568244\ttotal: 5.49s\tremaining: 24.8s\n",
      "172:\tlearn: 34.1288064\ttotal: 5.52s\tremaining: 24.8s\n",
      "173:\tlearn: 34.0930729\ttotal: 5.55s\tremaining: 24.7s\n",
      "174:\tlearn: 34.0632183\ttotal: 5.58s\tremaining: 24.7s\n",
      "175:\tlearn: 34.0340710\ttotal: 5.61s\tremaining: 24.6s\n",
      "176:\tlearn: 34.0062717\ttotal: 5.64s\tremaining: 24.6s\n",
      "177:\tlearn: 33.9822742\ttotal: 5.66s\tremaining: 24.5s\n",
      "178:\tlearn: 33.9518441\ttotal: 5.69s\tremaining: 24.5s\n",
      "179:\tlearn: 33.9269082\ttotal: 5.72s\tremaining: 24.4s\n",
      "180:\tlearn: 33.9028104\ttotal: 5.75s\tremaining: 24.4s\n",
      "181:\tlearn: 33.8774271\ttotal: 5.78s\tremaining: 24.3s\n",
      "182:\tlearn: 33.8517556\ttotal: 5.8s\tremaining: 24.3s\n",
      "183:\tlearn: 33.8284326\ttotal: 5.83s\tremaining: 24.2s\n",
      "184:\tlearn: 33.7961642\ttotal: 5.86s\tremaining: 24.2s\n",
      "185:\tlearn: 33.7649153\ttotal: 5.89s\tremaining: 24.2s\n",
      "186:\tlearn: 33.7417345\ttotal: 5.92s\tremaining: 24.1s\n",
      "187:\tlearn: 33.7194826\ttotal: 5.94s\tremaining: 24.1s\n",
      "188:\tlearn: 33.6971383\ttotal: 5.97s\tremaining: 24s\n",
      "189:\tlearn: 33.6754945\ttotal: 6s\tremaining: 24s\n",
      "190:\tlearn: 33.6527745\ttotal: 6.03s\tremaining: 23.9s\n",
      "191:\tlearn: 33.6269289\ttotal: 6.06s\tremaining: 23.9s\n",
      "192:\tlearn: 33.6020460\ttotal: 6.09s\tremaining: 23.8s\n",
      "193:\tlearn: 33.5838916\ttotal: 6.11s\tremaining: 23.8s\n",
      "194:\tlearn: 33.5618397\ttotal: 6.14s\tremaining: 23.8s\n",
      "195:\tlearn: 33.5402033\ttotal: 6.17s\tremaining: 23.7s\n",
      "196:\tlearn: 33.5216480\ttotal: 6.2s\tremaining: 23.7s\n",
      "197:\tlearn: 33.4974537\ttotal: 6.23s\tremaining: 23.6s\n",
      "198:\tlearn: 33.4781734\ttotal: 6.28s\tremaining: 23.7s\n",
      "199:\tlearn: 33.4502518\ttotal: 6.32s\tremaining: 23.6s\n",
      "200:\tlearn: 33.4303202\ttotal: 6.35s\tremaining: 23.6s\n",
      "201:\tlearn: 33.4083110\ttotal: 6.38s\tremaining: 23.6s\n",
      "202:\tlearn: 33.3809198\ttotal: 6.41s\tremaining: 23.6s\n",
      "203:\tlearn: 33.3519346\ttotal: 6.45s\tremaining: 23.5s\n",
      "204:\tlearn: 33.3321482\ttotal: 6.48s\tremaining: 23.5s\n",
      "205:\tlearn: 33.3062401\ttotal: 6.51s\tremaining: 23.5s\n",
      "206:\tlearn: 33.2902444\ttotal: 6.55s\tremaining: 23.5s\n",
      "207:\tlearn: 33.2681977\ttotal: 6.58s\tremaining: 23.4s\n",
      "208:\tlearn: 33.2498392\ttotal: 6.61s\tremaining: 23.4s\n",
      "209:\tlearn: 33.2347150\ttotal: 6.64s\tremaining: 23.4s\n",
      "210:\tlearn: 33.2184104\ttotal: 6.67s\tremaining: 23.3s\n",
      "211:\tlearn: 33.2015813\ttotal: 6.7s\tremaining: 23.3s\n",
      "212:\tlearn: 33.1876494\ttotal: 6.72s\tremaining: 23.2s\n",
      "213:\tlearn: 33.1717591\ttotal: 6.75s\tremaining: 23.2s\n",
      "214:\tlearn: 33.1515571\ttotal: 6.78s\tremaining: 23.1s\n",
      "215:\tlearn: 33.1359086\ttotal: 6.81s\tremaining: 23.1s\n",
      "216:\tlearn: 33.1154376\ttotal: 6.83s\tremaining: 23.1s\n",
      "217:\tlearn: 33.0884711\ttotal: 6.86s\tremaining: 23s\n",
      "218:\tlearn: 33.0623049\ttotal: 6.88s\tremaining: 23s\n",
      "219:\tlearn: 33.0410030\ttotal: 6.91s\tremaining: 22.9s\n",
      "220:\tlearn: 33.0185309\ttotal: 6.94s\tremaining: 22.9s\n",
      "221:\tlearn: 33.0058092\ttotal: 6.96s\tremaining: 22.8s\n",
      "222:\tlearn: 32.9866470\ttotal: 6.99s\tremaining: 22.8s\n",
      "223:\tlearn: 32.9674939\ttotal: 7.02s\tremaining: 22.7s\n",
      "224:\tlearn: 32.9446284\ttotal: 7.05s\tremaining: 22.7s\n",
      "225:\tlearn: 32.9301660\ttotal: 7.08s\tremaining: 22.6s\n",
      "226:\tlearn: 32.9121111\ttotal: 7.11s\tremaining: 22.6s\n",
      "227:\tlearn: 32.8963745\ttotal: 7.14s\tremaining: 22.6s\n",
      "228:\tlearn: 32.8782918\ttotal: 7.17s\tremaining: 22.5s\n",
      "229:\tlearn: 32.8582685\ttotal: 7.2s\tremaining: 22.5s\n",
      "230:\tlearn: 32.8460392\ttotal: 7.22s\tremaining: 22.5s\n",
      "231:\tlearn: 32.8267361\ttotal: 7.25s\tremaining: 22.4s\n",
      "232:\tlearn: 32.8123962\ttotal: 7.28s\tremaining: 22.4s\n",
      "233:\tlearn: 32.7987368\ttotal: 7.31s\tremaining: 22.3s\n",
      "234:\tlearn: 32.7787129\ttotal: 7.34s\tremaining: 22.3s\n",
      "235:\tlearn: 32.7663043\ttotal: 7.37s\tremaining: 22.3s\n",
      "236:\tlearn: 32.7536979\ttotal: 7.39s\tremaining: 22.2s\n",
      "237:\tlearn: 32.7366226\ttotal: 7.42s\tremaining: 22.2s\n",
      "238:\tlearn: 32.7238441\ttotal: 7.45s\tremaining: 22.1s\n",
      "239:\tlearn: 32.7053039\ttotal: 7.47s\tremaining: 22.1s\n",
      "240:\tlearn: 32.6884551\ttotal: 7.5s\tremaining: 22s\n",
      "241:\tlearn: 32.6752578\ttotal: 7.53s\tremaining: 22s\n",
      "242:\tlearn: 32.6603802\ttotal: 7.57s\tremaining: 22s\n",
      "243:\tlearn: 32.6445194\ttotal: 7.6s\tremaining: 22s\n",
      "244:\tlearn: 32.6317085\ttotal: 7.63s\tremaining: 21.9s\n",
      "245:\tlearn: 32.6141317\ttotal: 7.66s\tremaining: 21.9s\n",
      "246:\tlearn: 32.5895709\ttotal: 7.7s\tremaining: 21.9s\n",
      "247:\tlearn: 32.5748059\ttotal: 7.72s\tremaining: 21.8s\n",
      "248:\tlearn: 32.5551144\ttotal: 7.75s\tremaining: 21.8s\n",
      "249:\tlearn: 32.5386632\ttotal: 7.78s\tremaining: 21.8s\n",
      "250:\tlearn: 32.5262814\ttotal: 7.81s\tremaining: 21.7s\n",
      "251:\tlearn: 32.5102396\ttotal: 7.84s\tremaining: 21.7s\n",
      "252:\tlearn: 32.4974972\ttotal: 7.87s\tremaining: 21.6s\n",
      "253:\tlearn: 32.4859577\ttotal: 7.9s\tremaining: 21.6s\n",
      "254:\tlearn: 32.4728872\ttotal: 7.92s\tremaining: 21.6s\n",
      "255:\tlearn: 32.4551263\ttotal: 7.95s\tremaining: 21.5s\n",
      "256:\tlearn: 32.4456153\ttotal: 7.98s\tremaining: 21.5s\n",
      "257:\tlearn: 32.4345364\ttotal: 8.01s\tremaining: 21.5s\n",
      "258:\tlearn: 32.4227093\ttotal: 8.04s\tremaining: 21.4s\n",
      "259:\tlearn: 32.4115819\ttotal: 8.07s\tremaining: 21.4s\n",
      "260:\tlearn: 32.3998576\ttotal: 8.1s\tremaining: 21.3s\n",
      "261:\tlearn: 32.3884365\ttotal: 8.12s\tremaining: 21.3s\n",
      "262:\tlearn: 32.3744559\ttotal: 8.15s\tremaining: 21.3s\n",
      "263:\tlearn: 32.3637417\ttotal: 8.17s\tremaining: 21.2s\n",
      "264:\tlearn: 32.3453232\ttotal: 8.2s\tremaining: 21.2s\n",
      "265:\tlearn: 32.3361149\ttotal: 8.23s\tremaining: 21.1s\n",
      "266:\tlearn: 32.3225261\ttotal: 8.26s\tremaining: 21.1s\n",
      "267:\tlearn: 32.3055017\ttotal: 8.29s\tremaining: 21.1s\n",
      "268:\tlearn: 32.2884794\ttotal: 8.31s\tremaining: 21s\n",
      "269:\tlearn: 32.2773428\ttotal: 8.34s\tremaining: 21s\n",
      "270:\tlearn: 32.2669489\ttotal: 8.37s\tremaining: 20.9s\n",
      "271:\tlearn: 32.2535193\ttotal: 8.4s\tremaining: 20.9s\n",
      "272:\tlearn: 32.2447867\ttotal: 8.43s\tremaining: 20.9s\n",
      "273:\tlearn: 32.2333725\ttotal: 8.46s\tremaining: 20.8s\n",
      "274:\tlearn: 32.2211561\ttotal: 8.49s\tremaining: 20.8s\n",
      "275:\tlearn: 32.2121600\ttotal: 8.52s\tremaining: 20.8s\n",
      "276:\tlearn: 32.2018484\ttotal: 8.54s\tremaining: 20.7s\n",
      "277:\tlearn: 32.1912975\ttotal: 8.57s\tremaining: 20.7s\n",
      "278:\tlearn: 32.1700394\ttotal: 8.6s\tremaining: 20.6s\n",
      "279:\tlearn: 32.1575342\ttotal: 8.63s\tremaining: 20.6s\n",
      "280:\tlearn: 32.1470661\ttotal: 8.65s\tremaining: 20.6s\n",
      "281:\tlearn: 32.1356408\ttotal: 8.68s\tremaining: 20.5s\n",
      "282:\tlearn: 32.1254901\ttotal: 8.71s\tremaining: 20.5s\n",
      "283:\tlearn: 32.1174354\ttotal: 8.74s\tremaining: 20.5s\n",
      "284:\tlearn: 32.1099745\ttotal: 8.77s\tremaining: 20.4s\n",
      "285:\tlearn: 32.0970305\ttotal: 8.8s\tremaining: 20.4s\n",
      "286:\tlearn: 32.0844644\ttotal: 8.83s\tremaining: 20.4s\n",
      "287:\tlearn: 32.0674531\ttotal: 8.85s\tremaining: 20.3s\n",
      "288:\tlearn: 32.0560516\ttotal: 8.88s\tremaining: 20.3s\n",
      "289:\tlearn: 32.0456052\ttotal: 8.91s\tremaining: 20.3s\n",
      "290:\tlearn: 32.0305050\ttotal: 8.94s\tremaining: 20.2s\n",
      "291:\tlearn: 32.0177946\ttotal: 8.97s\tremaining: 20.2s\n",
      "292:\tlearn: 32.0044361\ttotal: 9s\tremaining: 20.1s\n",
      "293:\tlearn: 31.9901455\ttotal: 9.03s\tremaining: 20.1s\n",
      "294:\tlearn: 31.9799598\ttotal: 9.05s\tremaining: 20.1s\n",
      "295:\tlearn: 31.9690726\ttotal: 9.08s\tremaining: 20s\n",
      "296:\tlearn: 31.9554707\ttotal: 9.11s\tremaining: 20s\n",
      "297:\tlearn: 31.9440547\ttotal: 9.14s\tremaining: 20s\n",
      "298:\tlearn: 31.9315484\ttotal: 9.17s\tremaining: 19.9s\n",
      "299:\tlearn: 31.9227519\ttotal: 9.2s\tremaining: 19.9s\n",
      "300:\tlearn: 31.9137097\ttotal: 9.22s\tremaining: 19.9s\n",
      "301:\tlearn: 31.9040481\ttotal: 9.25s\tremaining: 19.8s\n",
      "302:\tlearn: 31.8894263\ttotal: 9.27s\tremaining: 19.8s\n",
      "303:\tlearn: 31.8725238\ttotal: 9.3s\tremaining: 19.7s\n",
      "304:\tlearn: 31.8629783\ttotal: 9.33s\tremaining: 19.7s\n",
      "305:\tlearn: 31.8549995\ttotal: 9.36s\tremaining: 19.7s\n",
      "306:\tlearn: 31.8472236\ttotal: 9.38s\tremaining: 19.6s\n",
      "307:\tlearn: 31.8365110\ttotal: 9.41s\tremaining: 19.6s\n",
      "308:\tlearn: 31.8295447\ttotal: 9.44s\tremaining: 19.6s\n",
      "309:\tlearn: 31.8166185\ttotal: 9.47s\tremaining: 19.5s\n",
      "310:\tlearn: 31.8078916\ttotal: 9.5s\tremaining: 19.5s\n",
      "311:\tlearn: 31.7989360\ttotal: 9.52s\tremaining: 19.4s\n",
      "312:\tlearn: 31.7885872\ttotal: 9.55s\tremaining: 19.4s\n",
      "313:\tlearn: 31.7703990\ttotal: 9.58s\tremaining: 19.4s\n",
      "314:\tlearn: 31.7558326\ttotal: 9.6s\tremaining: 19.3s\n",
      "315:\tlearn: 31.7496148\ttotal: 9.63s\tremaining: 19.3s\n",
      "316:\tlearn: 31.7404676\ttotal: 9.66s\tremaining: 19.3s\n",
      "317:\tlearn: 31.7313102\ttotal: 9.69s\tremaining: 19.2s\n",
      "318:\tlearn: 31.7221393\ttotal: 9.71s\tremaining: 19.2s\n",
      "319:\tlearn: 31.7087713\ttotal: 9.74s\tremaining: 19.1s\n",
      "320:\tlearn: 31.6919223\ttotal: 9.77s\tremaining: 19.1s\n",
      "321:\tlearn: 31.6779924\ttotal: 9.79s\tremaining: 19.1s\n",
      "322:\tlearn: 31.6650662\ttotal: 9.82s\tremaining: 19s\n",
      "323:\tlearn: 31.6571560\ttotal: 9.85s\tremaining: 19s\n",
      "324:\tlearn: 31.6467335\ttotal: 9.88s\tremaining: 19s\n",
      "325:\tlearn: 31.6401999\ttotal: 9.9s\tremaining: 18.9s\n",
      "326:\tlearn: 31.6271403\ttotal: 9.94s\tremaining: 18.9s\n",
      "327:\tlearn: 31.6205467\ttotal: 9.96s\tremaining: 18.9s\n",
      "328:\tlearn: 31.6091216\ttotal: 9.99s\tremaining: 18.8s\n",
      "329:\tlearn: 31.5994961\ttotal: 10s\tremaining: 18.8s\n",
      "330:\tlearn: 31.5920776\ttotal: 10.1s\tremaining: 18.8s\n",
      "331:\tlearn: 31.5777863\ttotal: 10.1s\tremaining: 18.7s\n",
      "332:\tlearn: 31.5679013\ttotal: 10.1s\tremaining: 18.7s\n",
      "333:\tlearn: 31.5544760\ttotal: 10.1s\tremaining: 18.7s\n",
      "334:\tlearn: 31.5333903\ttotal: 10.2s\tremaining: 18.6s\n",
      "335:\tlearn: 31.5252092\ttotal: 10.2s\tremaining: 18.6s\n",
      "336:\tlearn: 31.5179190\ttotal: 10.2s\tremaining: 18.6s\n",
      "337:\tlearn: 31.5098247\ttotal: 10.2s\tremaining: 18.5s\n",
      "338:\tlearn: 31.4998102\ttotal: 10.3s\tremaining: 18.5s\n",
      "339:\tlearn: 31.4845947\ttotal: 10.3s\tremaining: 18.4s\n",
      "340:\tlearn: 31.4740769\ttotal: 10.3s\tremaining: 18.4s\n",
      "341:\tlearn: 31.4650415\ttotal: 10.4s\tremaining: 18.4s\n",
      "342:\tlearn: 31.4515732\ttotal: 10.4s\tremaining: 18.3s\n",
      "343:\tlearn: 31.4438265\ttotal: 10.4s\tremaining: 18.3s\n",
      "344:\tlearn: 31.4326627\ttotal: 10.4s\tremaining: 18.3s\n",
      "345:\tlearn: 31.4192335\ttotal: 10.5s\tremaining: 18.2s\n",
      "346:\tlearn: 31.4077641\ttotal: 10.5s\tremaining: 18.2s\n",
      "347:\tlearn: 31.3919405\ttotal: 10.5s\tremaining: 18.2s\n",
      "348:\tlearn: 31.3740050\ttotal: 10.5s\tremaining: 18.1s\n",
      "349:\tlearn: 31.3653540\ttotal: 10.6s\tremaining: 18.1s\n",
      "350:\tlearn: 31.3498236\ttotal: 10.6s\tremaining: 18.1s\n",
      "351:\tlearn: 31.3430137\ttotal: 10.6s\tremaining: 18s\n",
      "352:\tlearn: 31.3336004\ttotal: 10.7s\tremaining: 18s\n",
      "353:\tlearn: 31.3189525\ttotal: 10.7s\tremaining: 18s\n",
      "354:\tlearn: 31.3073437\ttotal: 10.7s\tremaining: 17.9s\n",
      "355:\tlearn: 31.2955027\ttotal: 10.7s\tremaining: 17.9s\n",
      "356:\tlearn: 31.2855816\ttotal: 10.8s\tremaining: 17.9s\n",
      "357:\tlearn: 31.2748594\ttotal: 10.8s\tremaining: 17.8s\n",
      "358:\tlearn: 31.2599431\ttotal: 10.8s\tremaining: 17.8s\n",
      "359:\tlearn: 31.2529995\ttotal: 10.8s\tremaining: 17.7s\n",
      "360:\tlearn: 31.2412765\ttotal: 10.9s\tremaining: 17.7s\n",
      "361:\tlearn: 31.2292665\ttotal: 10.9s\tremaining: 17.7s\n",
      "362:\tlearn: 31.2210183\ttotal: 10.9s\tremaining: 17.6s\n",
      "363:\tlearn: 31.2086576\ttotal: 10.9s\tremaining: 17.6s\n",
      "364:\tlearn: 31.1946305\ttotal: 11s\tremaining: 17.6s\n",
      "365:\tlearn: 31.1886249\ttotal: 11s\tremaining: 17.5s\n",
      "366:\tlearn: 31.1765230\ttotal: 11s\tremaining: 17.5s\n",
      "367:\tlearn: 31.1663619\ttotal: 11.1s\tremaining: 17.5s\n",
      "368:\tlearn: 31.1609762\ttotal: 11.1s\tremaining: 17.4s\n",
      "369:\tlearn: 31.1457403\ttotal: 11.1s\tremaining: 17.4s\n",
      "370:\tlearn: 31.1394939\ttotal: 11.1s\tremaining: 17.4s\n",
      "371:\tlearn: 31.1348117\ttotal: 11.2s\tremaining: 17.3s\n",
      "372:\tlearn: 31.1277092\ttotal: 11.2s\tremaining: 17.3s\n",
      "373:\tlearn: 31.1216426\ttotal: 11.2s\tremaining: 17.3s\n",
      "374:\tlearn: 31.1116857\ttotal: 11.3s\tremaining: 17.2s\n",
      "375:\tlearn: 31.0930894\ttotal: 11.3s\tremaining: 17.2s\n",
      "376:\tlearn: 31.0845606\ttotal: 11.3s\tremaining: 17.2s\n",
      "377:\tlearn: 31.0722968\ttotal: 11.3s\tremaining: 17.1s\n",
      "378:\tlearn: 31.0669530\ttotal: 11.4s\tremaining: 17.1s\n",
      "379:\tlearn: 31.0544176\ttotal: 11.4s\tremaining: 17s\n",
      "380:\tlearn: 31.0480891\ttotal: 11.4s\tremaining: 17s\n",
      "381:\tlearn: 31.0408553\ttotal: 11.4s\tremaining: 17s\n",
      "382:\tlearn: 31.0309159\ttotal: 11.5s\tremaining: 16.9s\n",
      "383:\tlearn: 31.0210039\ttotal: 11.5s\tremaining: 16.9s\n",
      "384:\tlearn: 31.0095445\ttotal: 11.5s\tremaining: 16.9s\n",
      "385:\tlearn: 30.9967854\ttotal: 11.5s\tremaining: 16.8s\n",
      "386:\tlearn: 30.9890640\ttotal: 11.6s\tremaining: 16.8s\n",
      "387:\tlearn: 30.9779887\ttotal: 11.6s\tremaining: 16.8s\n",
      "388:\tlearn: 30.9701233\ttotal: 11.6s\tremaining: 16.7s\n",
      "389:\tlearn: 30.9603816\ttotal: 11.6s\tremaining: 16.7s\n",
      "390:\tlearn: 30.9504357\ttotal: 11.7s\tremaining: 16.7s\n",
      "391:\tlearn: 30.9395324\ttotal: 11.7s\tremaining: 16.6s\n",
      "392:\tlearn: 30.9295589\ttotal: 11.7s\tremaining: 16.6s\n",
      "393:\tlearn: 30.9220988\ttotal: 11.8s\tremaining: 16.6s\n",
      "394:\tlearn: 30.9117722\ttotal: 11.8s\tremaining: 16.5s\n",
      "395:\tlearn: 30.9004998\ttotal: 11.8s\tremaining: 16.5s\n",
      "396:\tlearn: 30.8925715\ttotal: 11.8s\tremaining: 16.5s\n",
      "397:\tlearn: 30.8837261\ttotal: 11.9s\tremaining: 16.4s\n",
      "398:\tlearn: 30.8726910\ttotal: 11.9s\tremaining: 16.4s\n",
      "399:\tlearn: 30.8554717\ttotal: 11.9s\tremaining: 16.4s\n",
      "400:\tlearn: 30.8479869\ttotal: 12s\tremaining: 16.3s\n",
      "401:\tlearn: 30.8392525\ttotal: 12s\tremaining: 16.3s\n",
      "402:\tlearn: 30.8354605\ttotal: 12s\tremaining: 16.3s\n",
      "403:\tlearn: 30.8190511\ttotal: 12s\tremaining: 16.2s\n",
      "404:\tlearn: 30.8054471\ttotal: 12.1s\tremaining: 16.2s\n",
      "405:\tlearn: 30.7978717\ttotal: 12.1s\tremaining: 16.2s\n",
      "406:\tlearn: 30.7885485\ttotal: 12.1s\tremaining: 16.1s\n",
      "407:\tlearn: 30.7795692\ttotal: 12.1s\tremaining: 16.1s\n",
      "408:\tlearn: 30.7753090\ttotal: 12.2s\tremaining: 16.1s\n",
      "409:\tlearn: 30.7610966\ttotal: 12.2s\tremaining: 16s\n",
      "410:\tlearn: 30.7436417\ttotal: 12.2s\tremaining: 16s\n",
      "411:\tlearn: 30.7295499\ttotal: 12.3s\tremaining: 16s\n",
      "412:\tlearn: 30.7159927\ttotal: 12.3s\tremaining: 15.9s\n",
      "413:\tlearn: 30.7025620\ttotal: 12.3s\tremaining: 15.9s\n",
      "414:\tlearn: 30.6871902\ttotal: 12.3s\tremaining: 15.9s\n",
      "415:\tlearn: 30.6805341\ttotal: 12.4s\tremaining: 15.8s\n",
      "416:\tlearn: 30.6722266\ttotal: 12.4s\tremaining: 15.8s\n",
      "417:\tlearn: 30.6645587\ttotal: 12.4s\tremaining: 15.8s\n",
      "418:\tlearn: 30.6541561\ttotal: 12.4s\tremaining: 15.7s\n",
      "419:\tlearn: 30.6467006\ttotal: 12.5s\tremaining: 15.7s\n",
      "420:\tlearn: 30.6382921\ttotal: 12.5s\tremaining: 15.7s\n",
      "421:\tlearn: 30.6266990\ttotal: 12.5s\tremaining: 15.7s\n",
      "422:\tlearn: 30.6158588\ttotal: 12.6s\tremaining: 15.6s\n",
      "423:\tlearn: 30.6098136\ttotal: 12.6s\tremaining: 15.6s\n",
      "424:\tlearn: 30.6019579\ttotal: 12.6s\tremaining: 15.6s\n",
      "425:\tlearn: 30.5940328\ttotal: 12.7s\tremaining: 15.5s\n",
      "426:\tlearn: 30.5858774\ttotal: 12.7s\tremaining: 15.5s\n",
      "427:\tlearn: 30.5780533\ttotal: 12.7s\tremaining: 15.5s\n",
      "428:\tlearn: 30.5674304\ttotal: 12.7s\tremaining: 15.4s\n",
      "429:\tlearn: 30.5603059\ttotal: 12.8s\tremaining: 15.4s\n",
      "430:\tlearn: 30.5491286\ttotal: 12.8s\tremaining: 15.4s\n",
      "431:\tlearn: 30.5357249\ttotal: 12.8s\tremaining: 15.4s\n",
      "432:\tlearn: 30.5259305\ttotal: 12.9s\tremaining: 15.3s\n",
      "433:\tlearn: 30.5178974\ttotal: 12.9s\tremaining: 15.3s\n",
      "434:\tlearn: 30.5055717\ttotal: 12.9s\tremaining: 15.3s\n",
      "435:\tlearn: 30.4973445\ttotal: 13s\tremaining: 15.2s\n",
      "436:\tlearn: 30.4878021\ttotal: 13s\tremaining: 15.2s\n",
      "437:\tlearn: 30.4785081\ttotal: 13s\tremaining: 15.2s\n",
      "438:\tlearn: 30.4688251\ttotal: 13s\tremaining: 15.2s\n",
      "439:\tlearn: 30.4563110\ttotal: 13.1s\tremaining: 15.1s\n",
      "440:\tlearn: 30.4498473\ttotal: 13.1s\tremaining: 15.1s\n",
      "441:\tlearn: 30.4380847\ttotal: 13.1s\tremaining: 15.1s\n",
      "442:\tlearn: 30.4289645\ttotal: 13.2s\tremaining: 15s\n",
      "443:\tlearn: 30.4180147\ttotal: 13.2s\tremaining: 15s\n",
      "444:\tlearn: 30.4098806\ttotal: 13.2s\tremaining: 15s\n",
      "445:\tlearn: 30.4024924\ttotal: 13.2s\tremaining: 14.9s\n",
      "446:\tlearn: 30.3947356\ttotal: 13.3s\tremaining: 14.9s\n",
      "447:\tlearn: 30.3888724\ttotal: 13.3s\tremaining: 14.9s\n",
      "448:\tlearn: 30.3774410\ttotal: 13.3s\tremaining: 14.8s\n",
      "449:\tlearn: 30.3714205\ttotal: 13.3s\tremaining: 14.8s\n",
      "450:\tlearn: 30.3655122\ttotal: 13.4s\tremaining: 14.8s\n",
      "451:\tlearn: 30.3566745\ttotal: 13.4s\tremaining: 14.7s\n",
      "452:\tlearn: 30.3469019\ttotal: 13.4s\tremaining: 14.7s\n",
      "453:\tlearn: 30.3368282\ttotal: 13.5s\tremaining: 14.7s\n",
      "454:\tlearn: 30.3278453\ttotal: 13.5s\tremaining: 14.6s\n",
      "455:\tlearn: 30.3170907\ttotal: 13.5s\tremaining: 14.6s\n",
      "456:\tlearn: 30.3067834\ttotal: 13.5s\tremaining: 14.6s\n",
      "457:\tlearn: 30.2976921\ttotal: 13.6s\tremaining: 14.5s\n",
      "458:\tlearn: 30.2840293\ttotal: 13.6s\tremaining: 14.5s\n",
      "459:\tlearn: 30.2734036\ttotal: 13.6s\tremaining: 14.5s\n",
      "460:\tlearn: 30.2666396\ttotal: 13.6s\tremaining: 14.4s\n",
      "461:\tlearn: 30.2580186\ttotal: 13.7s\tremaining: 14.4s\n",
      "462:\tlearn: 30.2452601\ttotal: 13.7s\tremaining: 14.4s\n",
      "463:\tlearn: 30.2338017\ttotal: 13.7s\tremaining: 14.4s\n",
      "464:\tlearn: 30.2232377\ttotal: 13.8s\tremaining: 14.3s\n",
      "465:\tlearn: 30.2150441\ttotal: 13.8s\tremaining: 14.3s\n",
      "466:\tlearn: 30.2094790\ttotal: 13.8s\tremaining: 14.3s\n",
      "467:\tlearn: 30.2026600\ttotal: 13.8s\tremaining: 14.2s\n",
      "468:\tlearn: 30.1886789\ttotal: 13.9s\tremaining: 14.2s\n",
      "469:\tlearn: 30.1815930\ttotal: 13.9s\tremaining: 14.2s\n",
      "470:\tlearn: 30.1751491\ttotal: 13.9s\tremaining: 14.1s\n",
      "471:\tlearn: 30.1688162\ttotal: 14s\tremaining: 14.1s\n",
      "472:\tlearn: 30.1600911\ttotal: 14s\tremaining: 14.1s\n",
      "473:\tlearn: 30.1475088\ttotal: 14s\tremaining: 14.1s\n",
      "474:\tlearn: 30.1408269\ttotal: 14.1s\tremaining: 14s\n",
      "475:\tlearn: 30.1345496\ttotal: 14.1s\tremaining: 14s\n",
      "476:\tlearn: 30.1259152\ttotal: 14.1s\tremaining: 14s\n",
      "477:\tlearn: 30.1160811\ttotal: 14.1s\tremaining: 13.9s\n",
      "478:\tlearn: 30.1045901\ttotal: 14.2s\tremaining: 13.9s\n",
      "479:\tlearn: 30.0980984\ttotal: 14.2s\tremaining: 13.9s\n",
      "480:\tlearn: 30.0884019\ttotal: 14.2s\tremaining: 13.8s\n",
      "481:\tlearn: 30.0819553\ttotal: 14.3s\tremaining: 13.8s\n",
      "482:\tlearn: 30.0695095\ttotal: 14.3s\tremaining: 13.8s\n",
      "483:\tlearn: 30.0562921\ttotal: 14.3s\tremaining: 13.7s\n",
      "484:\tlearn: 30.0452585\ttotal: 14.3s\tremaining: 13.7s\n",
      "485:\tlearn: 30.0374286\ttotal: 14.4s\tremaining: 13.7s\n",
      "486:\tlearn: 30.0307357\ttotal: 14.4s\tremaining: 13.7s\n",
      "487:\tlearn: 30.0200423\ttotal: 14.4s\tremaining: 13.6s\n",
      "488:\tlearn: 30.0140228\ttotal: 14.4s\tremaining: 13.6s\n",
      "489:\tlearn: 30.0081932\ttotal: 14.5s\tremaining: 13.6s\n",
      "490:\tlearn: 29.9977473\ttotal: 14.5s\tremaining: 13.5s\n",
      "491:\tlearn: 29.9895966\ttotal: 14.5s\tremaining: 13.5s\n",
      "492:\tlearn: 29.9799683\ttotal: 14.5s\tremaining: 13.5s\n",
      "493:\tlearn: 29.9738529\ttotal: 14.6s\tremaining: 13.4s\n",
      "494:\tlearn: 29.9674342\ttotal: 14.6s\tremaining: 13.4s\n",
      "495:\tlearn: 29.9590747\ttotal: 14.6s\tremaining: 13.4s\n",
      "496:\tlearn: 29.9540076\ttotal: 14.7s\tremaining: 13.3s\n",
      "497:\tlearn: 29.9464512\ttotal: 14.7s\tremaining: 13.3s\n",
      "498:\tlearn: 29.9416092\ttotal: 14.7s\tremaining: 13.3s\n",
      "499:\tlearn: 29.9329746\ttotal: 14.7s\tremaining: 13.2s\n",
      "500:\tlearn: 29.9198963\ttotal: 14.8s\tremaining: 13.2s\n",
      "501:\tlearn: 29.9113259\ttotal: 14.8s\tremaining: 13.2s\n",
      "502:\tlearn: 29.9035188\ttotal: 14.8s\tremaining: 13.1s\n",
      "503:\tlearn: 29.8971451\ttotal: 14.9s\tremaining: 13.1s\n",
      "504:\tlearn: 29.8825400\ttotal: 14.9s\tremaining: 13.1s\n",
      "505:\tlearn: 29.8747812\ttotal: 14.9s\tremaining: 13.1s\n",
      "506:\tlearn: 29.8684897\ttotal: 14.9s\tremaining: 13s\n",
      "507:\tlearn: 29.8624413\ttotal: 15s\tremaining: 13s\n",
      "508:\tlearn: 29.8519682\ttotal: 15s\tremaining: 13s\n",
      "509:\tlearn: 29.8456603\ttotal: 15s\tremaining: 12.9s\n",
      "510:\tlearn: 29.8359258\ttotal: 15.1s\tremaining: 12.9s\n",
      "511:\tlearn: 29.8266694\ttotal: 15.1s\tremaining: 12.9s\n",
      "512:\tlearn: 29.8153038\ttotal: 15.1s\tremaining: 12.8s\n",
      "513:\tlearn: 29.8050090\ttotal: 15.1s\tremaining: 12.8s\n",
      "514:\tlearn: 29.8000174\ttotal: 15.2s\tremaining: 12.8s\n",
      "515:\tlearn: 29.7922193\ttotal: 15.2s\tremaining: 12.8s\n",
      "516:\tlearn: 29.7809791\ttotal: 15.2s\tremaining: 12.7s\n",
      "517:\tlearn: 29.7729600\ttotal: 15.3s\tremaining: 12.7s\n",
      "518:\tlearn: 29.7629915\ttotal: 15.3s\tremaining: 12.7s\n",
      "519:\tlearn: 29.7549916\ttotal: 15.3s\tremaining: 12.6s\n",
      "520:\tlearn: 29.7462024\ttotal: 15.3s\tremaining: 12.6s\n",
      "521:\tlearn: 29.7389124\ttotal: 15.4s\tremaining: 12.6s\n",
      "522:\tlearn: 29.7244079\ttotal: 15.4s\tremaining: 12.5s\n",
      "523:\tlearn: 29.7161551\ttotal: 15.4s\tremaining: 12.5s\n",
      "524:\tlearn: 29.7046145\ttotal: 15.5s\tremaining: 12.5s\n",
      "525:\tlearn: 29.6935661\ttotal: 15.5s\tremaining: 12.5s\n",
      "526:\tlearn: 29.6861888\ttotal: 15.5s\tremaining: 12.4s\n",
      "527:\tlearn: 29.6756016\ttotal: 15.6s\tremaining: 12.4s\n",
      "528:\tlearn: 29.6661601\ttotal: 15.6s\tremaining: 12.4s\n",
      "529:\tlearn: 29.6548781\ttotal: 15.6s\tremaining: 12.4s\n",
      "530:\tlearn: 29.6451921\ttotal: 15.7s\tremaining: 12.3s\n",
      "531:\tlearn: 29.6350747\ttotal: 15.7s\tremaining: 12.3s\n",
      "532:\tlearn: 29.6273725\ttotal: 15.7s\tremaining: 12.3s\n",
      "533:\tlearn: 29.6192651\ttotal: 15.8s\tremaining: 12.2s\n",
      "534:\tlearn: 29.6079684\ttotal: 15.8s\tremaining: 12.2s\n",
      "535:\tlearn: 29.5973233\ttotal: 15.8s\tremaining: 12.2s\n",
      "536:\tlearn: 29.5888818\ttotal: 15.8s\tremaining: 12.2s\n",
      "537:\tlearn: 29.5831769\ttotal: 15.9s\tremaining: 12.1s\n",
      "538:\tlearn: 29.5770780\ttotal: 15.9s\tremaining: 12.1s\n",
      "539:\tlearn: 29.5675854\ttotal: 15.9s\tremaining: 12.1s\n",
      "540:\tlearn: 29.5581684\ttotal: 15.9s\tremaining: 12s\n",
      "541:\tlearn: 29.5501630\ttotal: 16s\tremaining: 12s\n",
      "542:\tlearn: 29.5385146\ttotal: 16s\tremaining: 12s\n",
      "543:\tlearn: 29.5272298\ttotal: 16s\tremaining: 11.9s\n",
      "544:\tlearn: 29.5206067\ttotal: 16.1s\tremaining: 11.9s\n",
      "545:\tlearn: 29.5143165\ttotal: 16.1s\tremaining: 11.9s\n",
      "546:\tlearn: 29.5046094\ttotal: 16.1s\tremaining: 11.8s\n",
      "547:\tlearn: 29.4984543\ttotal: 16.1s\tremaining: 11.8s\n",
      "548:\tlearn: 29.4885918\ttotal: 16.2s\tremaining: 11.8s\n",
      "549:\tlearn: 29.4833798\ttotal: 16.2s\tremaining: 11.8s\n",
      "550:\tlearn: 29.4770655\ttotal: 16.2s\tremaining: 11.7s\n",
      "551:\tlearn: 29.4661290\ttotal: 16.3s\tremaining: 11.7s\n",
      "552:\tlearn: 29.4585319\ttotal: 16.3s\tremaining: 11.7s\n",
      "553:\tlearn: 29.4541473\ttotal: 16.3s\tremaining: 11.6s\n",
      "554:\tlearn: 29.4448142\ttotal: 16.3s\tremaining: 11.6s\n",
      "555:\tlearn: 29.4327327\ttotal: 16.4s\tremaining: 11.6s\n",
      "556:\tlearn: 29.4236204\ttotal: 16.4s\tremaining: 11.5s\n",
      "557:\tlearn: 29.4098397\ttotal: 16.4s\tremaining: 11.5s\n",
      "558:\tlearn: 29.4034392\ttotal: 16.5s\tremaining: 11.5s\n",
      "559:\tlearn: 29.3968071\ttotal: 16.5s\tremaining: 11.5s\n",
      "560:\tlearn: 29.3858466\ttotal: 16.5s\tremaining: 11.4s\n",
      "561:\tlearn: 29.3742998\ttotal: 16.6s\tremaining: 11.4s\n",
      "562:\tlearn: 29.3661282\ttotal: 16.6s\tremaining: 11.4s\n",
      "563:\tlearn: 29.3581920\ttotal: 16.6s\tremaining: 11.3s\n",
      "564:\tlearn: 29.3476350\ttotal: 16.6s\tremaining: 11.3s\n",
      "565:\tlearn: 29.3419649\ttotal: 16.7s\tremaining: 11.3s\n",
      "566:\tlearn: 29.3363988\ttotal: 16.7s\tremaining: 11.3s\n",
      "567:\tlearn: 29.3306147\ttotal: 16.7s\tremaining: 11.2s\n",
      "568:\tlearn: 29.3199561\ttotal: 16.8s\tremaining: 11.2s\n",
      "569:\tlearn: 29.3070941\ttotal: 16.8s\tremaining: 11.2s\n",
      "570:\tlearn: 29.2961855\ttotal: 16.8s\tremaining: 11.2s\n",
      "571:\tlearn: 29.2863913\ttotal: 16.9s\tremaining: 11.1s\n",
      "572:\tlearn: 29.2789354\ttotal: 16.9s\tremaining: 11.1s\n",
      "573:\tlearn: 29.2699704\ttotal: 17s\tremaining: 11.1s\n",
      "574:\tlearn: 29.2570079\ttotal: 17s\tremaining: 11s\n",
      "575:\tlearn: 29.2492021\ttotal: 17s\tremaining: 11s\n",
      "576:\tlearn: 29.2442918\ttotal: 17s\tremaining: 11s\n",
      "577:\tlearn: 29.2391462\ttotal: 17.1s\tremaining: 11s\n",
      "578:\tlearn: 29.2315038\ttotal: 17.1s\tremaining: 10.9s\n",
      "579:\tlearn: 29.2245435\ttotal: 17.1s\tremaining: 10.9s\n",
      "580:\tlearn: 29.2148368\ttotal: 17.2s\tremaining: 10.9s\n",
      "581:\tlearn: 29.2039970\ttotal: 17.2s\tremaining: 10.8s\n",
      "582:\tlearn: 29.1964478\ttotal: 17.2s\tremaining: 10.8s\n",
      "583:\tlearn: 29.1849398\ttotal: 17.3s\tremaining: 10.8s\n",
      "584:\tlearn: 29.1789974\ttotal: 17.3s\tremaining: 10.8s\n",
      "585:\tlearn: 29.1718052\ttotal: 17.3s\tremaining: 10.7s\n",
      "586:\tlearn: 29.1671662\ttotal: 17.4s\tremaining: 10.7s\n",
      "587:\tlearn: 29.1588586\ttotal: 17.4s\tremaining: 10.7s\n",
      "588:\tlearn: 29.1521766\ttotal: 17.4s\tremaining: 10.7s\n",
      "589:\tlearn: 29.1456634\ttotal: 17.5s\tremaining: 10.6s\n",
      "590:\tlearn: 29.1401392\ttotal: 17.5s\tremaining: 10.6s\n",
      "591:\tlearn: 29.1293002\ttotal: 17.5s\tremaining: 10.6s\n",
      "592:\tlearn: 29.1212900\ttotal: 17.5s\tremaining: 10.5s\n",
      "593:\tlearn: 29.1123136\ttotal: 17.6s\tremaining: 10.5s\n",
      "594:\tlearn: 29.1029545\ttotal: 17.6s\tremaining: 10.5s\n",
      "595:\tlearn: 29.0934438\ttotal: 17.6s\tremaining: 10.4s\n",
      "596:\tlearn: 29.0858251\ttotal: 17.7s\tremaining: 10.4s\n",
      "597:\tlearn: 29.0778908\ttotal: 17.7s\tremaining: 10.4s\n",
      "598:\tlearn: 29.0718566\ttotal: 17.7s\tremaining: 10.4s\n",
      "599:\tlearn: 29.0673575\ttotal: 17.8s\tremaining: 10.3s\n",
      "600:\tlearn: 29.0566678\ttotal: 17.8s\tremaining: 10.3s\n",
      "601:\tlearn: 29.0495925\ttotal: 17.8s\tremaining: 10.3s\n",
      "602:\tlearn: 29.0444343\ttotal: 17.9s\tremaining: 10.2s\n",
      "603:\tlearn: 29.0308822\ttotal: 17.9s\tremaining: 10.2s\n",
      "604:\tlearn: 29.0241840\ttotal: 17.9s\tremaining: 10.2s\n",
      "605:\tlearn: 29.0180262\ttotal: 17.9s\tremaining: 10.2s\n",
      "606:\tlearn: 29.0109358\ttotal: 18s\tremaining: 10.1s\n",
      "607:\tlearn: 29.0026783\ttotal: 18s\tremaining: 10.1s\n",
      "608:\tlearn: 28.9937142\ttotal: 18.1s\tremaining: 10.1s\n",
      "609:\tlearn: 28.9798902\ttotal: 18.1s\tremaining: 10.1s\n",
      "610:\tlearn: 28.9697288\ttotal: 18.1s\tremaining: 10s\n",
      "611:\tlearn: 28.9618496\ttotal: 18.2s\tremaining: 10s\n",
      "612:\tlearn: 28.9524456\ttotal: 18.2s\tremaining: 9.98s\n",
      "613:\tlearn: 28.9413485\ttotal: 18.2s\tremaining: 9.96s\n",
      "614:\tlearn: 28.9345073\ttotal: 18.3s\tremaining: 9.93s\n",
      "615:\tlearn: 28.9262215\ttotal: 18.3s\tremaining: 9.9s\n",
      "616:\tlearn: 28.9191584\ttotal: 18.3s\tremaining: 9.87s\n",
      "617:\tlearn: 28.9121282\ttotal: 18.4s\tremaining: 9.84s\n",
      "618:\tlearn: 28.9025604\ttotal: 18.4s\tremaining: 9.81s\n",
      "619:\tlearn: 28.8905271\ttotal: 18.4s\tremaining: 9.78s\n",
      "620:\tlearn: 28.8798362\ttotal: 18.5s\tremaining: 9.75s\n",
      "621:\tlearn: 28.8688619\ttotal: 18.5s\tremaining: 9.72s\n",
      "622:\tlearn: 28.8582365\ttotal: 18.5s\tremaining: 9.7s\n",
      "623:\tlearn: 28.8493333\ttotal: 18.6s\tremaining: 9.67s\n",
      "624:\tlearn: 28.8367890\ttotal: 18.6s\tremaining: 9.64s\n",
      "625:\tlearn: 28.8299263\ttotal: 18.6s\tremaining: 9.61s\n",
      "626:\tlearn: 28.8242410\ttotal: 18.7s\tremaining: 9.58s\n",
      "627:\tlearn: 28.8147872\ttotal: 18.7s\tremaining: 9.55s\n",
      "628:\tlearn: 28.8068906\ttotal: 18.7s\tremaining: 9.52s\n",
      "629:\tlearn: 28.8001771\ttotal: 18.7s\tremaining: 9.49s\n",
      "630:\tlearn: 28.7924541\ttotal: 18.8s\tremaining: 9.46s\n",
      "631:\tlearn: 28.7854586\ttotal: 18.8s\tremaining: 9.43s\n",
      "632:\tlearn: 28.7796094\ttotal: 18.8s\tremaining: 9.4s\n",
      "633:\tlearn: 28.7709037\ttotal: 18.9s\tremaining: 9.37s\n",
      "634:\tlearn: 28.7648771\ttotal: 18.9s\tremaining: 9.34s\n",
      "635:\tlearn: 28.7558773\ttotal: 18.9s\tremaining: 9.31s\n",
      "636:\tlearn: 28.7497184\ttotal: 18.9s\tremaining: 9.28s\n",
      "637:\tlearn: 28.7430486\ttotal: 19s\tremaining: 9.25s\n",
      "638:\tlearn: 28.7352253\ttotal: 19s\tremaining: 9.22s\n",
      "639:\tlearn: 28.7275774\ttotal: 19s\tremaining: 9.19s\n",
      "640:\tlearn: 28.7231513\ttotal: 19.1s\tremaining: 9.16s\n",
      "641:\tlearn: 28.7184834\ttotal: 19.1s\tremaining: 9.13s\n",
      "642:\tlearn: 28.7108762\ttotal: 19.1s\tremaining: 9.11s\n",
      "643:\tlearn: 28.7011913\ttotal: 19.2s\tremaining: 9.08s\n",
      "644:\tlearn: 28.6955723\ttotal: 19.2s\tremaining: 9.05s\n",
      "645:\tlearn: 28.6903476\ttotal: 19.2s\tremaining: 9.02s\n",
      "646:\tlearn: 28.6830713\ttotal: 19.3s\tremaining: 8.99s\n",
      "647:\tlearn: 28.6742966\ttotal: 19.3s\tremaining: 8.96s\n",
      "648:\tlearn: 28.6661471\ttotal: 19.3s\tremaining: 8.93s\n",
      "649:\tlearn: 28.6582744\ttotal: 19.3s\tremaining: 8.9s\n",
      "650:\tlearn: 28.6490055\ttotal: 19.4s\tremaining: 8.87s\n",
      "651:\tlearn: 28.6404696\ttotal: 19.4s\tremaining: 8.84s\n",
      "652:\tlearn: 28.6319354\ttotal: 19.4s\tremaining: 8.81s\n",
      "653:\tlearn: 28.6263064\ttotal: 19.5s\tremaining: 8.78s\n",
      "654:\tlearn: 28.6194286\ttotal: 19.5s\tremaining: 8.75s\n",
      "655:\tlearn: 28.6115029\ttotal: 19.5s\tremaining: 8.72s\n",
      "656:\tlearn: 28.6012361\ttotal: 19.6s\tremaining: 8.69s\n",
      "657:\tlearn: 28.5934014\ttotal: 19.6s\tremaining: 8.66s\n",
      "658:\tlearn: 28.5812793\ttotal: 19.6s\tremaining: 8.63s\n",
      "659:\tlearn: 28.5739417\ttotal: 19.6s\tremaining: 8.6s\n",
      "660:\tlearn: 28.5672209\ttotal: 19.7s\tremaining: 8.57s\n",
      "661:\tlearn: 28.5600779\ttotal: 19.7s\tremaining: 8.54s\n",
      "662:\tlearn: 28.5465079\ttotal: 19.7s\tremaining: 8.51s\n",
      "663:\tlearn: 28.5376575\ttotal: 19.8s\tremaining: 8.48s\n",
      "664:\tlearn: 28.5298020\ttotal: 19.8s\tremaining: 8.45s\n",
      "665:\tlearn: 28.5232144\ttotal: 19.8s\tremaining: 8.42s\n",
      "666:\tlearn: 28.5138962\ttotal: 19.9s\tremaining: 8.39s\n",
      "667:\tlearn: 28.5045424\ttotal: 19.9s\tremaining: 8.36s\n",
      "668:\tlearn: 28.4916607\ttotal: 19.9s\tremaining: 8.33s\n",
      "669:\tlearn: 28.4811039\ttotal: 19.9s\tremaining: 8.3s\n",
      "670:\tlearn: 28.4718095\ttotal: 20s\tremaining: 8.27s\n",
      "671:\tlearn: 28.4621573\ttotal: 20s\tremaining: 8.24s\n",
      "672:\tlearn: 28.4517667\ttotal: 20s\tremaining: 8.21s\n",
      "673:\tlearn: 28.4460966\ttotal: 20s\tremaining: 8.18s\n",
      "674:\tlearn: 28.4370594\ttotal: 20.1s\tremaining: 8.15s\n",
      "675:\tlearn: 28.4272201\ttotal: 20.1s\tremaining: 8.12s\n",
      "676:\tlearn: 28.4223766\ttotal: 20.1s\tremaining: 8.09s\n",
      "677:\tlearn: 28.4148937\ttotal: 20.2s\tremaining: 8.06s\n",
      "678:\tlearn: 28.4094804\ttotal: 20.2s\tremaining: 8.03s\n",
      "679:\tlearn: 28.3992199\ttotal: 20.2s\tremaining: 8s\n",
      "680:\tlearn: 28.3905583\ttotal: 20.3s\tremaining: 7.97s\n",
      "681:\tlearn: 28.3837544\ttotal: 20.3s\tremaining: 7.94s\n",
      "682:\tlearn: 28.3739531\ttotal: 20.3s\tremaining: 7.91s\n",
      "683:\tlearn: 28.3655141\ttotal: 20.3s\tremaining: 7.88s\n",
      "684:\tlearn: 28.3582320\ttotal: 20.4s\tremaining: 7.85s\n",
      "685:\tlearn: 28.3506756\ttotal: 20.4s\tremaining: 7.82s\n",
      "686:\tlearn: 28.3441355\ttotal: 20.4s\tremaining: 7.79s\n",
      "687:\tlearn: 28.3351668\ttotal: 20.5s\tremaining: 7.77s\n",
      "688:\tlearn: 28.3293431\ttotal: 20.5s\tremaining: 7.74s\n",
      "689:\tlearn: 28.3212256\ttotal: 20.5s\tremaining: 7.71s\n",
      "690:\tlearn: 28.3148929\ttotal: 20.6s\tremaining: 7.68s\n",
      "691:\tlearn: 28.3065694\ttotal: 20.6s\tremaining: 7.66s\n",
      "692:\tlearn: 28.3009077\ttotal: 20.7s\tremaining: 7.63s\n",
      "693:\tlearn: 28.2934497\ttotal: 20.7s\tremaining: 7.61s\n",
      "694:\tlearn: 28.2817461\ttotal: 20.7s\tremaining: 7.58s\n",
      "695:\tlearn: 28.2696715\ttotal: 20.8s\tremaining: 7.55s\n",
      "696:\tlearn: 28.2627476\ttotal: 20.8s\tremaining: 7.52s\n",
      "697:\tlearn: 28.2518082\ttotal: 20.8s\tremaining: 7.5s\n",
      "698:\tlearn: 28.2464827\ttotal: 20.9s\tremaining: 7.47s\n",
      "699:\tlearn: 28.2389489\ttotal: 20.9s\tremaining: 7.44s\n",
      "700:\tlearn: 28.2316110\ttotal: 20.9s\tremaining: 7.41s\n",
      "701:\tlearn: 28.2202506\ttotal: 21s\tremaining: 7.38s\n",
      "702:\tlearn: 28.2118219\ttotal: 21s\tremaining: 7.35s\n",
      "703:\tlearn: 28.1985552\ttotal: 21s\tremaining: 7.32s\n",
      "704:\tlearn: 28.1926717\ttotal: 21.1s\tremaining: 7.29s\n",
      "705:\tlearn: 28.1859701\ttotal: 21.1s\tremaining: 7.26s\n",
      "706:\tlearn: 28.1765052\ttotal: 21.1s\tremaining: 7.23s\n",
      "707:\tlearn: 28.1685549\ttotal: 21.2s\tremaining: 7.2s\n",
      "708:\tlearn: 28.1636500\ttotal: 21.2s\tremaining: 7.17s\n",
      "709:\tlearn: 28.1571619\ttotal: 21.2s\tremaining: 7.14s\n",
      "710:\tlearn: 28.1508380\ttotal: 21.2s\tremaining: 7.11s\n",
      "711:\tlearn: 28.1452072\ttotal: 21.3s\tremaining: 7.08s\n",
      "712:\tlearn: 28.1390377\ttotal: 21.3s\tremaining: 7.05s\n",
      "713:\tlearn: 28.1343841\ttotal: 21.3s\tremaining: 7.02s\n",
      "714:\tlearn: 28.1276605\ttotal: 21.4s\tremaining: 6.99s\n",
      "715:\tlearn: 28.1224396\ttotal: 21.4s\tremaining: 6.96s\n",
      "716:\tlearn: 28.1164665\ttotal: 21.4s\tremaining: 6.93s\n",
      "717:\tlearn: 28.1099763\ttotal: 21.4s\tremaining: 6.9s\n",
      "718:\tlearn: 28.1041829\ttotal: 21.5s\tremaining: 6.87s\n",
      "719:\tlearn: 28.0922445\ttotal: 21.5s\tremaining: 6.84s\n",
      "720:\tlearn: 28.0871453\ttotal: 21.5s\tremaining: 6.81s\n",
      "721:\tlearn: 28.0782101\ttotal: 21.6s\tremaining: 6.78s\n",
      "722:\tlearn: 28.0683886\ttotal: 21.6s\tremaining: 6.75s\n",
      "723:\tlearn: 28.0592188\ttotal: 21.6s\tremaining: 6.72s\n",
      "724:\tlearn: 28.0518417\ttotal: 21.6s\tremaining: 6.69s\n",
      "725:\tlearn: 28.0377742\ttotal: 21.7s\tremaining: 6.66s\n",
      "726:\tlearn: 28.0316420\ttotal: 21.7s\tremaining: 6.63s\n",
      "727:\tlearn: 28.0251745\ttotal: 21.7s\tremaining: 6.6s\n",
      "728:\tlearn: 28.0187621\ttotal: 21.8s\tremaining: 6.57s\n",
      "729:\tlearn: 28.0110639\ttotal: 21.8s\tremaining: 6.54s\n",
      "730:\tlearn: 28.0039227\ttotal: 21.8s\tremaining: 6.51s\n",
      "731:\tlearn: 27.9993220\ttotal: 21.9s\tremaining: 6.48s\n",
      "732:\tlearn: 27.9890604\ttotal: 21.9s\tremaining: 6.45s\n",
      "733:\tlearn: 27.9818107\ttotal: 21.9s\tremaining: 6.43s\n",
      "734:\tlearn: 27.9739769\ttotal: 22s\tremaining: 6.4s\n",
      "735:\tlearn: 27.9621633\ttotal: 22s\tremaining: 6.37s\n",
      "736:\tlearn: 27.9519521\ttotal: 22s\tremaining: 6.34s\n",
      "737:\tlearn: 27.9439997\ttotal: 22.1s\tremaining: 6.31s\n",
      "738:\tlearn: 27.9359621\ttotal: 22.1s\tremaining: 6.28s\n",
      "739:\tlearn: 27.9297390\ttotal: 22.1s\tremaining: 6.25s\n",
      "740:\tlearn: 27.9212902\ttotal: 22.2s\tremaining: 6.22s\n",
      "741:\tlearn: 27.9146361\ttotal: 22.2s\tremaining: 6.2s\n",
      "742:\tlearn: 27.9074946\ttotal: 22.2s\tremaining: 6.17s\n",
      "743:\tlearn: 27.8960563\ttotal: 22.3s\tremaining: 6.14s\n",
      "744:\tlearn: 27.8909279\ttotal: 22.3s\tremaining: 6.11s\n",
      "745:\tlearn: 27.8845685\ttotal: 22.3s\tremaining: 6.08s\n",
      "746:\tlearn: 27.8768416\ttotal: 22.4s\tremaining: 6.05s\n",
      "747:\tlearn: 27.8712148\ttotal: 22.4s\tremaining: 6.01s\n",
      "748:\tlearn: 27.8643298\ttotal: 22.4s\tremaining: 5.99s\n",
      "749:\tlearn: 27.8590699\ttotal: 22.4s\tremaining: 5.95s\n",
      "750:\tlearn: 27.8487941\ttotal: 22.5s\tremaining: 5.92s\n",
      "751:\tlearn: 27.8430256\ttotal: 22.5s\tremaining: 5.89s\n",
      "752:\tlearn: 27.8349771\ttotal: 22.5s\tremaining: 5.86s\n",
      "753:\tlearn: 27.8283958\ttotal: 22.6s\tremaining: 5.83s\n",
      "754:\tlearn: 27.8239902\ttotal: 22.6s\tremaining: 5.8s\n",
      "755:\tlearn: 27.8189585\ttotal: 22.6s\tremaining: 5.77s\n",
      "756:\tlearn: 27.8128347\ttotal: 22.6s\tremaining: 5.74s\n",
      "757:\tlearn: 27.8038565\ttotal: 22.7s\tremaining: 5.71s\n",
      "758:\tlearn: 27.7967369\ttotal: 22.7s\tremaining: 5.68s\n",
      "759:\tlearn: 27.7896364\ttotal: 22.7s\tremaining: 5.65s\n",
      "760:\tlearn: 27.7831868\ttotal: 22.8s\tremaining: 5.62s\n",
      "761:\tlearn: 27.7774643\ttotal: 22.8s\tremaining: 5.59s\n",
      "762:\tlearn: 27.7689196\ttotal: 22.8s\tremaining: 5.56s\n",
      "763:\tlearn: 27.7586976\ttotal: 22.8s\tremaining: 5.53s\n",
      "764:\tlearn: 27.7502520\ttotal: 22.9s\tremaining: 5.5s\n",
      "765:\tlearn: 27.7427600\ttotal: 22.9s\tremaining: 5.47s\n",
      "766:\tlearn: 27.7369474\ttotal: 22.9s\tremaining: 5.44s\n",
      "767:\tlearn: 27.7289526\ttotal: 23s\tremaining: 5.41s\n",
      "768:\tlearn: 27.7219703\ttotal: 23s\tremaining: 5.38s\n",
      "769:\tlearn: 27.7163953\ttotal: 23s\tremaining: 5.35s\n",
      "770:\tlearn: 27.7096179\ttotal: 23s\tremaining: 5.32s\n",
      "771:\tlearn: 27.7022544\ttotal: 23.1s\tremaining: 5.29s\n",
      "772:\tlearn: 27.6949097\ttotal: 23.1s\tremaining: 5.26s\n",
      "773:\tlearn: 27.6850616\ttotal: 23.1s\tremaining: 5.23s\n",
      "774:\tlearn: 27.6775164\ttotal: 23.2s\tremaining: 5.2s\n",
      "775:\tlearn: 27.6697778\ttotal: 23.2s\tremaining: 5.18s\n",
      "776:\tlearn: 27.6615742\ttotal: 23.3s\tremaining: 5.15s\n",
      "777:\tlearn: 27.6550566\ttotal: 23.3s\tremaining: 5.12s\n",
      "778:\tlearn: 27.6480453\ttotal: 23.4s\tremaining: 5.09s\n",
      "779:\tlearn: 27.6386298\ttotal: 23.4s\tremaining: 5.07s\n",
      "780:\tlearn: 27.6303839\ttotal: 23.4s\tremaining: 5.04s\n",
      "781:\tlearn: 27.6231894\ttotal: 23.4s\tremaining: 5.01s\n",
      "782:\tlearn: 27.6176557\ttotal: 23.5s\tremaining: 4.98s\n",
      "783:\tlearn: 27.6095931\ttotal: 23.5s\tremaining: 4.95s\n",
      "784:\tlearn: 27.6028505\ttotal: 23.5s\tremaining: 4.92s\n",
      "785:\tlearn: 27.5939676\ttotal: 23.6s\tremaining: 4.89s\n",
      "786:\tlearn: 27.5860697\ttotal: 23.6s\tremaining: 4.86s\n",
      "787:\tlearn: 27.5796120\ttotal: 23.6s\tremaining: 4.83s\n",
      "788:\tlearn: 27.5685733\ttotal: 23.7s\tremaining: 4.8s\n",
      "789:\tlearn: 27.5602666\ttotal: 23.7s\tremaining: 4.77s\n",
      "790:\tlearn: 27.5555652\ttotal: 23.7s\tremaining: 4.74s\n",
      "791:\tlearn: 27.5488132\ttotal: 23.7s\tremaining: 4.71s\n",
      "792:\tlearn: 27.5417206\ttotal: 23.8s\tremaining: 4.67s\n",
      "793:\tlearn: 27.5352453\ttotal: 23.8s\tremaining: 4.64s\n",
      "794:\tlearn: 27.5274553\ttotal: 23.8s\tremaining: 4.61s\n",
      "795:\tlearn: 27.5203429\ttotal: 23.8s\tremaining: 4.58s\n",
      "796:\tlearn: 27.5117004\ttotal: 23.9s\tremaining: 4.55s\n",
      "797:\tlearn: 27.5063700\ttotal: 23.9s\tremaining: 4.52s\n",
      "798:\tlearn: 27.5002494\ttotal: 23.9s\tremaining: 4.49s\n",
      "799:\tlearn: 27.4935302\ttotal: 24s\tremaining: 4.46s\n",
      "800:\tlearn: 27.4851371\ttotal: 24s\tremaining: 4.43s\n",
      "801:\tlearn: 27.4777613\ttotal: 24s\tremaining: 4.4s\n",
      "802:\tlearn: 27.4668200\ttotal: 24s\tremaining: 4.37s\n",
      "803:\tlearn: 27.4608540\ttotal: 24.1s\tremaining: 4.34s\n",
      "804:\tlearn: 27.4503186\ttotal: 24.1s\tremaining: 4.31s\n",
      "805:\tlearn: 27.4428902\ttotal: 24.1s\tremaining: 4.28s\n",
      "806:\tlearn: 27.4344292\ttotal: 24.2s\tremaining: 4.25s\n",
      "807:\tlearn: 27.4258455\ttotal: 24.2s\tremaining: 4.22s\n",
      "808:\tlearn: 27.4208732\ttotal: 24.2s\tremaining: 4.19s\n",
      "809:\tlearn: 27.4120300\ttotal: 24.2s\tremaining: 4.16s\n",
      "810:\tlearn: 27.4043705\ttotal: 24.3s\tremaining: 4.13s\n",
      "811:\tlearn: 27.3975617\ttotal: 24.3s\tremaining: 4.1s\n",
      "812:\tlearn: 27.3928663\ttotal: 24.3s\tremaining: 4.07s\n",
      "813:\tlearn: 27.3853422\ttotal: 24.4s\tremaining: 4.04s\n",
      "814:\tlearn: 27.3774292\ttotal: 24.4s\tremaining: 4.01s\n",
      "815:\tlearn: 27.3703719\ttotal: 24.4s\tremaining: 3.98s\n",
      "816:\tlearn: 27.3635031\ttotal: 24.5s\tremaining: 3.95s\n",
      "817:\tlearn: 27.3557103\ttotal: 24.5s\tremaining: 3.92s\n",
      "818:\tlearn: 27.3483690\ttotal: 24.6s\tremaining: 3.9s\n",
      "819:\tlearn: 27.3407331\ttotal: 24.6s\tremaining: 3.87s\n",
      "820:\tlearn: 27.3314159\ttotal: 24.6s\tremaining: 3.84s\n",
      "821:\tlearn: 27.3252848\ttotal: 24.7s\tremaining: 3.81s\n",
      "822:\tlearn: 27.3207325\ttotal: 24.7s\tremaining: 3.78s\n",
      "823:\tlearn: 27.3118017\ttotal: 24.8s\tremaining: 3.75s\n",
      "824:\tlearn: 27.3024412\ttotal: 24.8s\tremaining: 3.72s\n",
      "825:\tlearn: 27.2960176\ttotal: 24.8s\tremaining: 3.69s\n",
      "826:\tlearn: 27.2905490\ttotal: 24.8s\tremaining: 3.66s\n",
      "827:\tlearn: 27.2833607\ttotal: 24.9s\tremaining: 3.63s\n",
      "828:\tlearn: 27.2723737\ttotal: 24.9s\tremaining: 3.6s\n",
      "829:\tlearn: 27.2625373\ttotal: 24.9s\tremaining: 3.57s\n",
      "830:\tlearn: 27.2531065\ttotal: 25s\tremaining: 3.54s\n",
      "831:\tlearn: 27.2464153\ttotal: 25s\tremaining: 3.51s\n",
      "832:\tlearn: 27.2378996\ttotal: 25s\tremaining: 3.48s\n",
      "833:\tlearn: 27.2328579\ttotal: 25s\tremaining: 3.45s\n",
      "834:\tlearn: 27.2260227\ttotal: 25.1s\tremaining: 3.42s\n",
      "835:\tlearn: 27.2146495\ttotal: 25.1s\tremaining: 3.39s\n",
      "836:\tlearn: 27.2069432\ttotal: 25.1s\tremaining: 3.36s\n",
      "837:\tlearn: 27.2011996\ttotal: 25.2s\tremaining: 3.33s\n",
      "838:\tlearn: 27.1952146\ttotal: 25.2s\tremaining: 3.3s\n",
      "839:\tlearn: 27.1884897\ttotal: 25.2s\tremaining: 3.27s\n",
      "840:\tlearn: 27.1818411\ttotal: 25.2s\tremaining: 3.24s\n",
      "841:\tlearn: 27.1766541\ttotal: 25.3s\tremaining: 3.21s\n",
      "842:\tlearn: 27.1698849\ttotal: 25.3s\tremaining: 3.18s\n",
      "843:\tlearn: 27.1636242\ttotal: 25.3s\tremaining: 3.15s\n",
      "844:\tlearn: 27.1565377\ttotal: 25.4s\tremaining: 3.12s\n",
      "845:\tlearn: 27.1481612\ttotal: 25.4s\tremaining: 3.09s\n",
      "846:\tlearn: 27.1412849\ttotal: 25.4s\tremaining: 3.06s\n",
      "847:\tlearn: 27.1369088\ttotal: 25.4s\tremaining: 3.03s\n",
      "848:\tlearn: 27.1310945\ttotal: 25.5s\tremaining: 3s\n",
      "849:\tlearn: 27.1198400\ttotal: 25.5s\tremaining: 2.97s\n",
      "850:\tlearn: 27.1111450\ttotal: 25.5s\tremaining: 2.94s\n",
      "851:\tlearn: 27.1032332\ttotal: 25.6s\tremaining: 2.91s\n",
      "852:\tlearn: 27.0952397\ttotal: 25.6s\tremaining: 2.88s\n",
      "853:\tlearn: 27.0881585\ttotal: 25.6s\tremaining: 2.85s\n",
      "854:\tlearn: 27.0777839\ttotal: 25.6s\tremaining: 2.82s\n",
      "855:\tlearn: 27.0692334\ttotal: 25.7s\tremaining: 2.79s\n",
      "856:\tlearn: 27.0620525\ttotal: 25.7s\tremaining: 2.76s\n",
      "857:\tlearn: 27.0571167\ttotal: 25.7s\tremaining: 2.73s\n",
      "858:\tlearn: 27.0515143\ttotal: 25.8s\tremaining: 2.7s\n",
      "859:\tlearn: 27.0460083\ttotal: 25.8s\tremaining: 2.67s\n",
      "860:\tlearn: 27.0381624\ttotal: 25.8s\tremaining: 2.64s\n",
      "861:\tlearn: 27.0329245\ttotal: 25.8s\tremaining: 2.61s\n",
      "862:\tlearn: 27.0263770\ttotal: 25.9s\tremaining: 2.58s\n",
      "863:\tlearn: 27.0176480\ttotal: 25.9s\tremaining: 2.55s\n",
      "864:\tlearn: 27.0058240\ttotal: 25.9s\tremaining: 2.52s\n",
      "865:\tlearn: 26.9968127\ttotal: 26s\tremaining: 2.49s\n",
      "866:\tlearn: 26.9906276\ttotal: 26s\tremaining: 2.46s\n",
      "867:\tlearn: 26.9843234\ttotal: 26s\tremaining: 2.43s\n",
      "868:\tlearn: 26.9770867\ttotal: 26.1s\tremaining: 2.4s\n",
      "869:\tlearn: 26.9705942\ttotal: 26.1s\tremaining: 2.37s\n",
      "870:\tlearn: 26.9641000\ttotal: 26.1s\tremaining: 2.34s\n",
      "871:\tlearn: 26.9584263\ttotal: 26.1s\tremaining: 2.31s\n",
      "872:\tlearn: 26.9485013\ttotal: 26.2s\tremaining: 2.28s\n",
      "873:\tlearn: 26.9409074\ttotal: 26.2s\tremaining: 2.25s\n",
      "874:\tlearn: 26.9341604\ttotal: 26.2s\tremaining: 2.22s\n",
      "875:\tlearn: 26.9234764\ttotal: 26.3s\tremaining: 2.19s\n",
      "876:\tlearn: 26.9140177\ttotal: 26.3s\tremaining: 2.16s\n",
      "877:\tlearn: 26.9074811\ttotal: 26.3s\tremaining: 2.13s\n",
      "878:\tlearn: 26.9004307\ttotal: 26.4s\tremaining: 2.1s\n",
      "879:\tlearn: 26.8928197\ttotal: 26.4s\tremaining: 2.07s\n",
      "880:\tlearn: 26.8877236\ttotal: 26.4s\tremaining: 2.04s\n",
      "881:\tlearn: 26.8788073\ttotal: 26.5s\tremaining: 2.01s\n",
      "882:\tlearn: 26.8713644\ttotal: 26.5s\tremaining: 1.98s\n",
      "883:\tlearn: 26.8648932\ttotal: 26.5s\tremaining: 1.95s\n",
      "884:\tlearn: 26.8594743\ttotal: 26.6s\tremaining: 1.92s\n",
      "885:\tlearn: 26.8533756\ttotal: 26.6s\tremaining: 1.89s\n",
      "886:\tlearn: 26.8463207\ttotal: 26.6s\tremaining: 1.86s\n",
      "887:\tlearn: 26.8393573\ttotal: 26.6s\tremaining: 1.83s\n",
      "888:\tlearn: 26.8348766\ttotal: 26.7s\tremaining: 1.8s\n",
      "889:\tlearn: 26.8276930\ttotal: 26.7s\tremaining: 1.77s\n",
      "890:\tlearn: 26.8205857\ttotal: 26.7s\tremaining: 1.74s\n",
      "891:\tlearn: 26.8099854\ttotal: 26.8s\tremaining: 1.71s\n",
      "892:\tlearn: 26.8041008\ttotal: 26.8s\tremaining: 1.68s\n",
      "893:\tlearn: 26.7986606\ttotal: 26.8s\tremaining: 1.65s\n",
      "894:\tlearn: 26.7918121\ttotal: 26.8s\tremaining: 1.62s\n",
      "895:\tlearn: 26.7830508\ttotal: 26.9s\tremaining: 1.59s\n",
      "896:\tlearn: 26.7738543\ttotal: 26.9s\tremaining: 1.56s\n",
      "897:\tlearn: 26.7691418\ttotal: 26.9s\tremaining: 1.53s\n",
      "898:\tlearn: 26.7622698\ttotal: 27s\tremaining: 1.5s\n",
      "899:\tlearn: 26.7573013\ttotal: 27s\tremaining: 1.47s\n",
      "900:\tlearn: 26.7475680\ttotal: 27s\tremaining: 1.44s\n",
      "901:\tlearn: 26.7428696\ttotal: 27s\tremaining: 1.41s\n",
      "902:\tlearn: 26.7362780\ttotal: 27.1s\tremaining: 1.38s\n",
      "903:\tlearn: 26.7319365\ttotal: 27.1s\tremaining: 1.35s\n",
      "904:\tlearn: 26.7255971\ttotal: 27.2s\tremaining: 1.32s\n",
      "905:\tlearn: 26.7167815\ttotal: 27.2s\tremaining: 1.29s\n",
      "906:\tlearn: 26.7102194\ttotal: 27.3s\tremaining: 1.26s\n",
      "907:\tlearn: 26.7038766\ttotal: 27.3s\tremaining: 1.23s\n",
      "908:\tlearn: 26.6981356\ttotal: 27.3s\tremaining: 1.2s\n",
      "909:\tlearn: 26.6919122\ttotal: 27.4s\tremaining: 1.17s\n",
      "910:\tlearn: 26.6856922\ttotal: 27.4s\tremaining: 1.14s\n",
      "911:\tlearn: 26.6813427\ttotal: 27.4s\tremaining: 1.11s\n",
      "912:\tlearn: 26.6765328\ttotal: 27.5s\tremaining: 1.08s\n",
      "913:\tlearn: 26.6705754\ttotal: 27.5s\tremaining: 1.05s\n",
      "914:\tlearn: 26.6624142\ttotal: 27.5s\tremaining: 1.02s\n",
      "915:\tlearn: 26.6562534\ttotal: 27.6s\tremaining: 993ms\n",
      "916:\tlearn: 26.6493876\ttotal: 27.6s\tremaining: 963ms\n",
      "917:\tlearn: 26.6406159\ttotal: 27.6s\tremaining: 933ms\n",
      "918:\tlearn: 26.6338918\ttotal: 27.6s\tremaining: 902ms\n",
      "919:\tlearn: 26.6289256\ttotal: 27.7s\tremaining: 872ms\n",
      "920:\tlearn: 26.6232518\ttotal: 27.7s\tremaining: 842ms\n",
      "921:\tlearn: 26.6165960\ttotal: 27.7s\tremaining: 812ms\n",
      "922:\tlearn: 26.6066849\ttotal: 27.8s\tremaining: 782ms\n",
      "923:\tlearn: 26.5970852\ttotal: 27.8s\tremaining: 752ms\n",
      "924:\tlearn: 26.5880295\ttotal: 27.8s\tremaining: 722ms\n",
      "925:\tlearn: 26.5814686\ttotal: 27.9s\tremaining: 692ms\n",
      "926:\tlearn: 26.5715834\ttotal: 27.9s\tremaining: 662ms\n",
      "927:\tlearn: 26.5658211\ttotal: 27.9s\tremaining: 632ms\n",
      "928:\tlearn: 26.5608014\ttotal: 27.9s\tremaining: 602ms\n",
      "929:\tlearn: 26.5539412\ttotal: 28s\tremaining: 571ms\n",
      "930:\tlearn: 26.5468504\ttotal: 28s\tremaining: 541ms\n",
      "931:\tlearn: 26.5428396\ttotal: 28s\tremaining: 511ms\n",
      "932:\tlearn: 26.5364412\ttotal: 28.1s\tremaining: 481ms\n",
      "933:\tlearn: 26.5311431\ttotal: 28.1s\tremaining: 451ms\n",
      "934:\tlearn: 26.5246969\ttotal: 28.1s\tremaining: 421ms\n",
      "935:\tlearn: 26.5140234\ttotal: 28.1s\tremaining: 391ms\n",
      "936:\tlearn: 26.5072467\ttotal: 28.2s\tremaining: 361ms\n",
      "937:\tlearn: 26.4971559\ttotal: 28.2s\tremaining: 331ms\n",
      "938:\tlearn: 26.4885809\ttotal: 28.2s\tremaining: 301ms\n",
      "939:\tlearn: 26.4833585\ttotal: 28.3s\tremaining: 271ms\n",
      "940:\tlearn: 26.4728159\ttotal: 28.3s\tremaining: 241ms\n",
      "941:\tlearn: 26.4630689\ttotal: 28.3s\tremaining: 210ms\n",
      "942:\tlearn: 26.4547949\ttotal: 28.4s\tremaining: 180ms\n",
      "943:\tlearn: 26.4474016\ttotal: 28.4s\tremaining: 150ms\n",
      "944:\tlearn: 26.4378241\ttotal: 28.4s\tremaining: 120ms\n",
      "945:\tlearn: 26.4300057\ttotal: 28.4s\tremaining: 90.2ms\n",
      "946:\tlearn: 26.4215956\ttotal: 28.5s\tremaining: 60.1ms\n",
      "947:\tlearn: 26.4137817\ttotal: 28.5s\tremaining: 30.1ms\n",
      "948:\tlearn: 26.4078832\ttotal: 28.5s\tremaining: 0us\n",
      "\n",
      " BEST MODEL: CAT (RMSE=33.2895)\n",
      "\n",
      "Creating Ensemble (XGB + LGB + CAT)...\n",
      "\n",
      "ENSEMBLE RESULTS:\n",
      "  RMSE: 33.3613\n",
      "  MAE : 26.1844\n",
      "  MAPE: 15.09%\n",
      "\n",
      "Plotting feature importance for cat...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Building v3 (Optuna)  COMPLETE \n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# MODEL BUILDING v3 (OPTUNA + ENSEMBLE) - PATCHED VERSION\n",
    "# Compatible with all LightGBM versions (verbose removed)\n",
    "# ===========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libraries\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ===========================================================\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denom = np.where(y_true == 0, 1, y_true)\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape_val = mape(y_true, y_pred)\n",
    "    return rmse, mae, mape_val\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# LOAD DATA\n",
    "# ===========================================================\n",
    "\n",
    "print(\"Loading engineered datasets...\")\n",
    "train = pd.read_csv(\"../data/final_train_v2.csv\", parse_dates=[\"Date\"])\n",
    "test  = pd.read_csv(\"../data/final_test_v2.csv\",  parse_dates=[\"Date\"])\n",
    "\n",
    "train = train.sort_values([\"Product_Category\",\"Country\",\"Date\"])\n",
    "test  = test.sort_values([\"Product_Category\",\"Country\",\"Date\"])\n",
    "\n",
    "TARGET = \"Total_Purchases\"\n",
    "drop_cols = [\"Date\"]\n",
    "feature_cols = [c for c in train.columns if c not in drop_cols + [TARGET]]\n",
    "\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[TARGET].copy()\n",
    "\n",
    "X_test = test[feature_cols].copy()\n",
    "y_test = test[TARGET].copy()\n",
    "\n",
    "# ===========================================================\n",
    "# SCALING\n",
    "# ===========================================================\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols]  = scaler.transform(X_test[num_cols])\n",
    "joblib.dump(scaler, \"scaler_v3.joblib\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# OPTUNA HYPERPARAMETER TUNING\n",
    "# ===========================================================\n",
    "\n",
    "print(\"\\n===== Starting Optuna Optimization =====\\n\")\n",
    "\n",
    "best_models = {}\n",
    "best_scores = {}\n",
    "\n",
    "# ===========================================================\n",
    "# XGBOOST OPTUNA\n",
    "# ===========================================================\n",
    "\n",
    "def xgb_objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 1500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"random_state\": 42,\n",
    "        \"tree_method\": \"hist\"\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    rmse, _, _ = evaluate(y_test, preds)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "print(\"Optimizing XGBoost...\")\n",
    "xgb_study = optuna.create_study(direction=\"minimize\")\n",
    "xgb_study.optimize(xgb_objective, n_trials=25, timeout=600)\n",
    "\n",
    "best_xgb_params = xgb_study.best_params\n",
    "print(\"\\nBest XGBoost params:\", best_xgb_params)\n",
    "\n",
    "best_xgb_model = xgb.XGBRegressor(**best_xgb_params)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = best_xgb_model.predict(X_test)\n",
    "best_models[\"xgb\"] = best_xgb_model\n",
    "best_scores[\"xgb\"] = evaluate(y_test, xgb_preds)[0]\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# LIGHTGBM OPTUNA (PATCHED - verbose removed)\n",
    "# ===========================================================\n",
    "\n",
    "def lgb_objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 1500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50),\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train)  # PATCH: no verbose argument\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    rmse, _, _ = evaluate(y_test, preds)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "print(\"\\nOptimizing LightGBM...\")\n",
    "lgb_study = optuna.create_study(direction=\"minimize\")\n",
    "lgb_study.optimize(lgb_objective, n_trials=25, timeout=600)\n",
    "\n",
    "best_lgb_params = lgb_study.best_params\n",
    "print(\"\\nBest LightGBM params:\", best_lgb_params)\n",
    "\n",
    "best_lgb_model = lgb.LGBMRegressor(**best_lgb_params)\n",
    "best_lgb_model.fit(X_train, y_train)  # PATCH\n",
    "lgb_preds = best_lgb_model.predict(X_test)\n",
    "best_models[\"lgb\"] = best_lgb_model\n",
    "best_scores[\"lgb\"] = evaluate(y_test, lgb_preds)[0]\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# CATBOOST OPTUNA\n",
    "# ===========================================================\n",
    "\n",
    "def cat_objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 400, 1500),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10),\n",
    "        \"random_seed\": 42,\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"verbose\": False\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    rmse, _, _ = evaluate(y_test, preds)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "print(\"\\nOptimizing CatBoost...\")\n",
    "cat_study = optuna.create_study(direction=\"minimize\")\n",
    "cat_study.optimize(cat_objective, n_trials=25, timeout=600)\n",
    "\n",
    "best_cat_params = cat_study.best_params\n",
    "print(\"\\nBest CatBoost params:\", best_cat_params)\n",
    "\n",
    "best_cat_model = CatBoostRegressor(**best_cat_params)\n",
    "best_cat_model.fit(X_train, y_train)\n",
    "cat_preds = best_cat_model.predict(X_test)\n",
    "best_models[\"cat\"] = best_cat_model\n",
    "best_scores[\"cat\"] = evaluate(y_test, cat_preds)[0]\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# BEST MODEL SELECTION\n",
    "# ===========================================================\n",
    "\n",
    "best_model_name = min(best_scores, key=best_scores.get)\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"\\n BEST MODEL: {best_model_name.upper()} (RMSE={best_scores[best_model_name]:.4f})\")\n",
    "\n",
    "joblib.dump(best_model, \"best_model_v3.joblib\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# OPTIONAL ENSEMBLE (Improves accuracy)\n",
    "# ===========================================================\n",
    "\n",
    "print(\"\\nCreating Ensemble (XGB + LGB + CAT)...\")\n",
    "\n",
    "ensemble_preds = (\n",
    "    0.4 * xgb_preds +\n",
    "    0.3 * lgb_preds +\n",
    "    0.3 * cat_preds\n",
    ")\n",
    "\n",
    "rmse, mae, mape_val = evaluate(y_test, ensemble_preds)\n",
    "\n",
    "print(\"\\nENSEMBLE RESULTS:\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE : {mae:.4f}\")\n",
    "print(f\"  MAPE: {mape_val:.2f}%\")\n",
    "\n",
    "test[\"ensemble_pred\"] = ensemble_preds\n",
    "test.to_csv(\"test_predictions_v3.csv\", index=False)\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# FEATURE IMPORTANCE\n",
    "# ===========================================================\n",
    "\n",
    "def plot_importance(model, name):\n",
    "    try:\n",
    "        fi = model.feature_importances_\n",
    "        imp = pd.Series(fi, index=feature_cols).sort_values(ascending=False).head(25)\n",
    "        \n",
    "        plt.figure(figsize=(8,8))\n",
    "        sns.barplot(x=imp.values, y=imp.index, hue=imp.index, legend=False)\n",
    "        plt.title(f\"Feature Importance - {name}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{name}_importance_v3.png\")\n",
    "        plt.show()\n",
    "\n",
    "    except:\n",
    "        print(f\"No importance available for {name}\")\n",
    "\n",
    "\n",
    "print(f\"\\nPlotting feature importance for {best_model_name}...\")\n",
    "plot_importance(best_model, best_model_name)\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# DONE\n",
    "# ===========================================================\n",
    "\n",
    "print(\"\\nModel Building v3 (Optuna)  COMPLETE \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc98bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd76d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84313be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
