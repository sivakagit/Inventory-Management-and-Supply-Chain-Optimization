{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279bb030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# FEATURE ENGINEERING PIPELINE FOR DEMAND FORECASTING\n",
    "# ===========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"Loading cleaned dataset...\")\n",
    "df = pd.read_csv(\"../data/cleaned_retail_data.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "# ===========================================================\n",
    "# 1. DATE FEATURES\n",
    "# ===========================================================\n",
    "print(\"Creating date-based features...\")\n",
    "\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "df['weekday'] = df['Date'].dt.weekday\n",
    "df['weekofyear'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n",
    "df['is_month_start'] = df['Date'].dt.is_month_start.astype(int)\n",
    "df['is_month_end'] = df['Date'].dt.is_month_end.astype(int)\n",
    "\n",
    "# ===========================================================\n",
    "# 2. DAILY AGGREGATION FOR FORECASTING\n",
    "# ===========================================================\n",
    "print(\"Aggregating to daily demand...\")\n",
    "\n",
    "daily = (\n",
    "    df.groupby(['Date','Product_Category','Country'])['Total_Purchases']\n",
    "      .sum()\n",
    "      .reset_index()\n",
    "      .sort_values(['Product_Category','Country','Date'])\n",
    ")\n",
    "\n",
    "# ===========================================================\n",
    "# 3. LAG FEATURES (7, 14, 21 DAYS)\n",
    "# ===========================================================\n",
    "print(\"Creating lag features...\")\n",
    "\n",
    "daily['lag_7'] = daily.groupby(['Product_Category','Country'])['Total_Purchases'].shift(7)\n",
    "daily['lag_14'] = daily.groupby(['Product_Category','Country'])['Total_Purchases'].shift(14)\n",
    "daily['lag_21'] = daily.groupby(['Product_Category','Country'])['Total_Purchases'].shift(21)\n",
    "\n",
    "# ===========================================================\n",
    "# 4. ROLLING FEATURES (7 & 14 DAYS)\n",
    "# ===========================================================\n",
    "print(\"Creating rolling-window features...\")\n",
    "\n",
    "daily['roll_mean_7'] = daily.groupby(['Product_Category','Country'])['Total_Purchases'].shift(1).rolling(7).mean()\n",
    "daily['roll_std_7']  = daily.groupby(['Product_Category','Country'])['Total_Purchases'].shift(1).rolling(7).std()\n",
    "\n",
    "daily['roll_mean_14'] = daily.groupby(['Product_Category','Country'])['Total_Purchases'].shift(1).rolling(14).mean()\n",
    "daily['roll_std_14']  = daily.groupby(['Product_Category','Country'])['Total_Purchases'].shift(1).rolling(14).std()\n",
    "\n",
    "# ===========================================================\n",
    "# 5. TRAIN/TEST SPLIT (LAST 60 DAYS = TEST)\n",
    "# ===========================================================\n",
    "print(\"Creating train/test split...\")\n",
    "\n",
    "split_date = daily['Date'].max() - pd.Timedelta(days=60)\n",
    "daily_train = daily[daily['Date'] <= split_date].copy()\n",
    "daily_test  = daily[daily['Date']  > split_date].copy()\n",
    "\n",
    "# ===========================================================\n",
    "# 6. TOP-N PRODUCT GROUPING (TRAIN ONLY)\n",
    "# ===========================================================\n",
    "print(\"Applying TOP-N product grouping...\")\n",
    "\n",
    "TOP_N = 50\n",
    "top_products = df['products'].value_counts().head(TOP_N).index.tolist()\n",
    "\n",
    "df['products_grouped'] = df['products'].apply(lambda x: x if x in top_products else 'OTHER')\n",
    "\n",
    "# merge product grouping into daily frames\n",
    "daily_train = daily_train.merge(\n",
    "    df[['Date','Product_Category','Country','products_grouped']],\n",
    "    on=['Date','Product_Category','Country'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "daily_test = daily_test.merge(\n",
    "    df[['Date','Product_Category','Country','products_grouped']],\n",
    "    on=['Date','Product_Category','Country'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ===========================================================\n",
    "# 7. FREQUENCY ENCODING (TRAIN ONLY)\n",
    "# ===========================================================\n",
    "print(\"Applying frequency encoding...\")\n",
    "\n",
    "freq = daily_train['products_grouped'].value_counts(normalize=True)\n",
    "daily_train['product_freq'] = daily_train['products_grouped'].map(freq)\n",
    "daily_test['product_freq']  = daily_test['products_grouped'].map(freq).fillna(0)\n",
    "\n",
    "# ===========================================================\n",
    "# 8. TARGET ENCODING (TRAIN ONLY)\n",
    "# ===========================================================\n",
    "print(\"Applying target encoding...\")\n",
    "\n",
    "global_mean = daily_train['Total_Purchases'].mean()\n",
    "target_enc = daily_train.groupby('products_grouped')['Total_Purchases'].mean()\n",
    "\n",
    "daily_train['product_target_enc'] = daily_train['products_grouped'].map(target_enc)\n",
    "daily_test['product_target_enc']  = daily_test['products_grouped'].map(target_enc).fillna(global_mean)\n",
    "\n",
    "# ===========================================================\n",
    "# 9. LABEL ENCODING FOR CATEGORY + COUNTRY\n",
    "# ===========================================================\n",
    "print(\"Label encoding category and country...\")\n",
    "\n",
    "LE_cols = ['Product_Category','Country','products_grouped']\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in LE_cols:\n",
    "    daily_train[col] = le.fit_transform(daily_train[col].astype(str))\n",
    "    daily_test[col]  = le.transform(daily_test[col].astype(str))\n",
    "\n",
    "# ===========================================================\n",
    "# 10. DROP NA ROWS CAUSED BY LAGS\n",
    "# ===========================================================\n",
    "print(\"Dropping NA lag rows...\")\n",
    "\n",
    "daily_train = daily_train.dropna().reset_index(drop=True)\n",
    "daily_test  = daily_test.dropna().reset_index(drop=True)\n",
    "\n",
    "# ===========================================================\n",
    "# 11. SAVE FINAL DATASETS\n",
    "# ===========================================================\n",
    "print(\"Saving final engineered datasets...\")\n",
    "\n",
    "daily_train.to_csv(\"final_train.csv\", index=False)\n",
    "daily_test.to_csv(\"final_test.csv\", index=False)\n",
    "\n",
    "print(\"Feature Engineering Complete âœ“\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
